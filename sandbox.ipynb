{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# *Initial* **Setup**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Package** *Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.3.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sde_lib (from versions: none)\n",
      "ERROR: No matching distribution found for sde_lib\n"
     ]
    }
   ],
   "source": [
    "%pip install pydicom\n",
    "%pip install ipywidgets\n",
    "%pip install sde_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports (General)\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import requests\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Library Imports (Modelling)\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import scipy\n",
    "\n",
    "# Library Imports (Monitoring)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import timeit\n",
    "import warnings\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Imports (General)\n",
    "from pathlib import Path\n",
    "from ipywidgets import interactive, IntSlider\n",
    "\n",
    "# Function Imports (Modelling)\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Function Imports (Monitoring)\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Argument** *Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional 3D Video Diffusion Model Parser Initialization\n",
    "ncdiff_parser = argparse.ArgumentParser(\n",
    "    description = \"Non-Conditional 3D Diffusion Model\")\n",
    "ncdiff_parser.add_argument('--model_type', type = str,            # Chosen Model / Diffusion\n",
    "                            choices =  {'video_diffusion',\n",
    "                                        'blackout_diffusion',\n",
    "                                        'gamma_diffusion'},\n",
    "                            default = 'video_diffusion')\n",
    "ncdiff_parser.add_argument('--model_version', type = int,         # Model Version Index\n",
    "                            default = 0)\n",
    "ncdiff_parser.add_argument('--data_version', type = int,          # Dataset Version Index\n",
    "                            default = 0)\n",
    "settings = ncdiff_parser.parse_args(\"\")\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Directories and Path Arguments\n",
    "ncdiff_parser.add_argument('--reader_folderpath', type = str,         # Path for Dataset Reader Directory\n",
    "                            default = 'data/non_cond')\n",
    "ncdiff_parser.add_argument('--public_data_folderpath', type = str,    # Path for Private Dataset Directory\n",
    "                            default = \"X:/nas-ctm01/datasets/public/MEDICAL/Duke-Breast-Cancer-T1\")\n",
    "                            #default = \"../../datasets/public/MEDICAL/Duke-Breast-Cancer-T1\")\n",
    "ncdiff_parser.add_argument('--private_data_folderpath', type = str,   # Path for Private Dataset Directory\n",
    "                            default = \"X:/nas-ctm01/datasets/private/METABREST/T1W_Breast\")\n",
    "                            #default = '../../datasets/private/METABREST/T1W_Breast')\n",
    "\n",
    "# Directory | Model-Related Path Arguments\n",
    "ncdiff_parser.add_argument('--model_folderpath', type = str,          # Path for Model Architecture Directory\n",
    "                            default = f'models/{settings.model_type}')\n",
    "ncdiff_parser.add_argument('--script_folderpath', type = str,         # Path for Model Training & Testing Scripts Directory\n",
    "                            default = f'scripts/{settings.model_type}')\n",
    "ncdiff_parser.add_argument('--logs_folderpath', type = str,           # Path for Model Saving Directory\n",
    "                            default = f'logs/{settings.model_type}')\n",
    "    \n",
    "# ============================================================================================\n",
    "\n",
    "# Dataset | Dataset General Arguments\n",
    "ncdiff_parser.add_argument('--img_size', type = int,              # Generated Image Resolution\n",
    "                            default = 64)\n",
    "ncdiff_parser.add_argument('--num_slice', type = int,             # Number of 2D Slices in MRI\n",
    "                            default = 30)\n",
    "ncdiff_parser.add_argument('--data_prep', type = bool,            # Usage of Dataset Pre-Processing Control Value\n",
    "                            default = True)\n",
    "ncdiff_parser.add_argument('--h_flip', type = int,                # Percentage of Horizontally Flipped Subjects\n",
    "                            default = 50)\n",
    "\n",
    "# Dataset | Dataset Splitting Arguments\n",
    "ncdiff_parser.add_argument('--train_subj', type = int,            # Number of Random Subjects in Training Set\n",
    "                            default = 20)                         # PS: Input 0 for all Subjects in the Dataset\n",
    "ncdiff_parser.add_argument('--val_subj', type = int,              # Number of Random Subjects in Validation Set\n",
    "                            default = 0)\n",
    "ncdiff_parser.add_argument('--test_subj', type = int,             # Number of Random Subjects in Test Set\n",
    "                            default = 0)\n",
    "\n",
    "# Dataset | DataLoader Arguments\n",
    "ncdiff_parser.add_argument('--batch_size', type = int,            # DataLoader Batch Size Value\n",
    "                            default = 1)\n",
    "ncdiff_parser.add_argument('--shuffle', type = bool,              # DataLoader Subject Shuffling Control Value\n",
    "                            default = False)\n",
    "ncdiff_parser.add_argument('--num_workers', type = int,           # Number of DataLoader Workers\n",
    "                            default = 8)\n",
    "ncdiff_parser.add_argument('--num_fps', type = int,               # Number of Video Frames per Second\n",
    "                            default = 4)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Model | Architecture-Defining Arguments\n",
    "ncdiff_parser.add_argument('--seed', type = int,                  # Randomised Generational Seed\n",
    "                            default = 0)\n",
    "ncdiff_parser.add_argument('--dim', type = int,                   # Input Dimensionality (Not Necessary)\n",
    "                            default = 64)\n",
    "ncdiff_parser.add_argument('--num_channel', type = int,           # Number of Input Channels for Dataset\n",
    "                            default = 1)\n",
    "ncdiff_parser.add_argument('--mult_dim', type = tuple,            # Dimensionality for all Conditional Layers\n",
    "                            default = (1, 2, 4, 8))\n",
    "\n",
    "# Model | Training & Diffusion Arguments\n",
    "#ncdiff_parser.add_argument('--num_epochs', type = int,            # Number of Training Epochs\n",
    "#                            default = 30)\n",
    "ncdiff_parser.add_argument('--num_ts', type = int,                # Number of Scheduler Timesteps\n",
    "                            default = 300)\n",
    "ncdiff_parser.add_argument('--num_steps', type = int,             # Number of Diffusion Training Steps\n",
    "                            default = 10000)\n",
    "ncdiff_parser.add_argument('--lr_base', type = float,             # Base Learning Rate Value\n",
    "                            default = 1e-3)\n",
    "ncdiff_parser.add_argument('--save_interval', type = int,         # Number of Training Step Interval inbetween Image Saving\n",
    "                            default = 1000)\n",
    "ncdiff_parser.add_argument('--log_interval', type = int,          # Number of Training Step Interval inbetween Result Logging (not a joke i swear...)\n",
    "                                default = 100)\n",
    "ncdiff_parser.add_argument('--save_img', type = int,              # Square Root of Number of Images Saved for Manual Evaluation\n",
    "                                default = 2)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "settings = ncdiff_parser.parse_args(\"\")\n",
    "settings.device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional 3D Blackout Diffusion Model Parser Initialization\n",
    "blackout_diff_parser = argparse.ArgumentParser(\n",
    "    description = \"Non-Conditional 3D Blackout Diffusion Model\")\n",
    "blackout_diff_parser.add_argument(  '--model_type', type = str,            # Chosen Model / Diffusion\n",
    "                                    choices =  {'video_diffusion',\n",
    "                                                'blackout_diffusion',\n",
    "                                                'gamma_diffusion'},\n",
    "                                    default = 'blackout_diffusion')\n",
    "blackout_diff_parser.add_argument(  '--model_version', type = int,         # Model Version Index\n",
    "                                    default = 0)\n",
    "blackout_diff_parser.add_argument(  '--data_version', type = int,          # Dataset Version Index\n",
    "                                    default = 0)\n",
    "settings = blackout_diff_parser.parse_args(\"\")\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Directories and Path Arguments\n",
    "blackout_diff_parser.add_argument(  '--reader_folderpath', type = str,         # Path for Dataset Reader Directory\n",
    "                                    default = 'data/non_cond')\n",
    "blackout_diff_parser.add_argument(  '--public_data_folderpath', type = str,    # Path for Private Dataset Directory\n",
    "                                    default = \"X:/nas-ctm01/datasets/public/MEDICAL/Duke-Breast-Cancer-T1\")\n",
    "                                    #default = \"../../datasets/public/MEDICAL/Duke-Breast-Cancer-T1\")\n",
    "blackout_diff_parser.add_argument(  '--private_data_folderpath', type = str,   # Path for Private Dataset Directory\n",
    "                                    default = \"X:/nas-ctm01/datasets/private/METABREST/T1W_Breast\")\n",
    "                                    #default = '../../datasets/private/METABREST/T1W_Breast')\n",
    "\n",
    "# Directory | Model-Related Path Arguments\n",
    "blackout_diff_parser.add_argument(  '--model_folderpath', type = str,          # Path for Model Architecture Directory\n",
    "                                    default = f'models/{settings.model_type}')\n",
    "blackout_diff_parser.add_argument(  '--script_folderpath', type = str,         # Path for Model Training & Testing Scripts Directory\n",
    "                                    default = f'scripts/{settings.model_type}')\n",
    "blackout_diff_parser.add_argument(  '--logs_folderpath', type = str,           # Path for Model Saving Directory\n",
    "                                    default = f'logs/{settings.model_type}')\n",
    "    \n",
    "# ============================================================================================\n",
    "\n",
    "# Dataset | Dataset General Arguments\n",
    "blackout_diff_parser.add_argument(  '--img_size', type = int,              # Generated Image Resolution\n",
    "                                    default = 64)\n",
    "blackout_diff_parser.add_argument(  '--num_slice', type = int,             # Number of 2D Slices in MRI\n",
    "                                    default = 30)\n",
    "blackout_diff_parser.add_argument(  '--data_prep', type = bool,            # Usage of Dataset Pre-Processing Control Value\n",
    "                                    default = True)\n",
    "blackout_diff_parser.add_argument(  '--h_flip', type = int,                # Percentage of Horizontally Flipped Subjects\n",
    "                                    default = 50)\n",
    "\n",
    "# Dataset | Dataset Splitting Arguments\n",
    "blackout_diff_parser.add_argument(  '--train_subj', type = int,            # Number of Random Subjects in Training Set\n",
    "                                    default = 20)                          # PS: Input 0 for all Subjects in the Dataset\n",
    "blackout_diff_parser.add_argument(  '--val_subj', type = int,              # Number of Random Subjects in Validation Set\n",
    "                                    default = 0)\n",
    "blackout_diff_parser.add_argument(  '--test_subj', type = int,             # Number of Random Subjects in Test Set\n",
    "                                    default = 0)\n",
    "\n",
    "# Dataset | DataLoader Arguments\n",
    "blackout_diff_parser.add_argument(  '--batch_size', type = int,            # DataLoader Batch Size Value\n",
    "                                    default = 1)\n",
    "blackout_diff_parser.add_argument(  '--shuffle', type = bool,              # DataLoader Subject Shuffling Control Value\n",
    "                                    default = False)\n",
    "blackout_diff_parser.add_argument(  '--num_workers', type = int,           # Number of DataLoader Workers\n",
    "                                    default = 8)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Model | Architecture-Defining Arguments\n",
    "blackout_diff_parser.add_argument(  '--seed', type = int,                  # Randomised Generational Seed\n",
    "                                    default = 0)\n",
    "blackout_diff_parser.add_argument(  '--dim', type = int,                   # Input Dimensionality (Not Necessary)\n",
    "                                    default = 64)\n",
    "blackout_diff_parser.add_argument(  '--num_channel', type = int,           # Number of Input Channels for Dataset\n",
    "                                    default = 1)\n",
    "blackout_diff_parser.add_argument(  '--mult_dim', type = tuple,            # Dimensionality for all Conditional Layers\n",
    "                                    default = (1, 2, 4, 8))\n",
    "\n",
    "# Model | Diffusion Arguments\n",
    "#blackout_diff_parser.add_argument('--num_epochs', type = int,            # Number of Training Epochs\n",
    "#                            default = 30)\n",
    "blackout_diff_parser.add_argument(  '--num_ts', type = int,                # Number of Scheduler Timesteps\n",
    "                                    default = 1)\n",
    "blackout_diff_parser.add_argument(  '--num_head', type = int,              # \n",
    "                                    default = 8)\n",
    "blackout_diff_parser.add_argument(  '--num_bucker', type = int,            # \n",
    "                                    default = 32)\n",
    "blackout_diff_parser.add_argument(  '--max_dist', type = int,              # \n",
    "                                    default = 128)\n",
    "blackout_diff_parser.add_argument(  '--ts_end', type = float,              # \n",
    "                                    default = 10.)\n",
    "blackout_diff_parser.add_argument(  '--offset', type = float,              # \n",
    "                                    default = 0.01)\n",
    "blackout_diff_parser.add_argument(  '--noise_thresh', type = float,        # \n",
    "                                    default = 0.5)\n",
    "\n",
    "# Model | Training Arguments\n",
    "#blackout_diff_parser.add_argument('--num_epochs', type = int,            # Number of Training Epochs\n",
    "#                                   default = 30)\n",
    "blackout_diff_parser.add_argument(  '--num_steps', type = int,             # Number of Diffusion Training Steps\n",
    "                                    default = 10000)\n",
    "blackout_diff_parser.add_argument(  '--lr_base', type = float,             # Base Learning Rate Value\n",
    "                                    default = 1e-3)\n",
    "blackout_diff_parser.add_argument(  '--save_interval', type = int,         # Number of Training Step Interval inbetween Image Saving\n",
    "                                    default = 1000)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "settings = blackout_diff_parser.parse_args(\"\")\n",
    "settings.device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# *Dataset* **Access**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Raw** *Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Station\n",
    "patient_id = 26\n",
    "patient_pos = 'OFP'\n",
    "num_slice = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'OFP/ID26'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset Access\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m slice_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpatient_pos\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ID\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpatient_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ID\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslice_list[num_slice]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m pydicom\u001b[38;5;241m.\u001b[39mdcmread(data_filepath)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'OFP/ID26'"
     ]
    }
   ],
   "source": [
    "# Dataset Access\n",
    "slice_list = os.listdir(f'{patient_pos}/ID{patient_id}')\n",
    "data_filepath = f\"{patient_pos}/ID{patient_id}/{slice_list[num_slice]}\"\n",
    "raw_data = pydicom.dcmread(data_filepath)\n",
    "pixel_data = raw_data.pixel_array\n",
    "\n",
    "# Meta Data Initialization\n",
    "#meta_filepath = \"ID1/S201-I-_PRIM_M_SE_T1W_TSE-20170324/annotFile_bkp.mat\"\n",
    "#meta_data = scipy.io.loadmat(meta_filepath)\n",
    "#pixel_data = np.frombuffer(raw_data.PixelData)\n",
    "#pixel_data = pydicom.data.get_testdata_file(data_filepath)\n",
    "\n",
    "# Important Information Access\n",
    "#assert(meta_data['cnt3dYXZ'].shape[2] == len(slice_filepath) - 1)\n",
    "assert(pixel_data.shape[0] == raw_data.Rows)\n",
    "assert(pixel_data.shape[1] == raw_data.Columns)\n",
    "print(f\"Patient Position: {str(raw_data[0x0018, 0x5100].value)}\")\n",
    "if patient_pos == 'External':\n",
    "    print(f\"Number of Slices: {int(len(slice_list))}\")\n",
    "    print(f\"Slice Number: {int(raw_data[0x0020, 0x0013].value)}\")\n",
    "else:\n",
    "    print(f\"Number of Slices: {int(raw_data[0x2001, 0x1018].value)}\")\n",
    "    print(f\"Slice Number: {int(raw_data[0x2001, 0x100a].value)}\")\n",
    "    print(f\"Series Number: {int(raw_data.SeriesNumber)}\")\n",
    "\n",
    "#print(meta_data['cnt3dYXZ'].shape)\n",
    "print(pixel_data.shape)\n",
    "plt.imshow(pixel_data, cmap = plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Positoning: FFP ; FFP\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "FFP: (0008, 0012) Instance Creation Date              DA: '20170321'\n",
      "OFP: (0008, 0012) Instance Creation Date              DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0013) Instance Creation Time              TM: '171934.980'\n",
      "OFP: (0008, 0013) Instance Creation Time              TM: '175555.355'\n",
      "\n",
      "FFP: (0008, 0018) SOP Instance UID                    UI: 1.3.46.670589.11.71641.5.0.1828.2017032116111778586\n",
      "OFP: (0008, 0018) SOP Instance UID                    UI: 1.3.46.670589.11.71641.5.0.4680.2017071816470843561\n",
      "\n",
      "FFP: (0008, 0020) Study Date                          DA: '20170321'\n",
      "OFP: (0008, 0020) Study Date                          DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0021) Series Date                         DA: '20170321'\n",
      "OFP: (0008, 0021) Series Date                         DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0022) Acquisition Date                    DA: '20170321'\n",
      "OFP: (0008, 0022) Acquisition Date                    DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0023) Content Date                        DA: '20170321'\n",
      "OFP: (0008, 0023) Content Date                        DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0030) Study Time                          TM: '160418'\n",
      "OFP: (0008, 0030) Study Time                          TM: '163911'\n",
      "\n",
      "FFP: (0008, 0031) Series Time                         TM: '160713.93000'\n",
      "OFP: (0008, 0031) Series Time                         TM: '164253.65000'\n",
      "\n",
      "FFP: (0008, 0032) Acquisition Time                    TM: '160722.82'\n",
      "OFP: (0008, 0032) Acquisition Time                    TM: '164302.40'\n",
      "\n",
      "FFP: (0008, 0033) Content Time                        TM: '160722.82'\n",
      "OFP: (0008, 0033) Content Time                        TM: '164302.40'\n",
      "\n",
      "FFP: (0008, 0050) Accession Number                    SH: '2017017868'\n",
      "OFP: (0008, 0050) Accession Number                    SH: '2017044005'\n",
      "\n",
      "FFP: (0008, 1111) Referenced Performed Procedure Step SQ: <Sequence, length 1>\n",
      "OFP: (0008, 1111) Referenced Performed Procedure Step SQ: <Sequence, length 1>\n",
      "\n",
      "FFP: (0008, 0012) Instance Creation Date              DA: '20170321'\n",
      "OFP: (0008, 0012) Instance Creation Date              DA: '20170718'\n",
      "\n",
      "FFP: (0008, 0013) Instance Creation Time              TM: '160418.395'\n",
      "OFP: (0008, 0013) Instance Creation Time              TM: '163911.905'\n",
      "\n",
      "FFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.11376.2017032116041839003\n",
      "OFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.10984.2017071816391190017\n",
      "\n",
      "FFP: (0008, 1140) Referenced Image Sequence           SQ: <Sequence, length 3>\n",
      "OFP: (0008, 1140) Referenced Image Sequence           SQ: <Sequence, length 3>\n",
      "\n",
      "FFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.1828.2017032116054257558\n",
      "OFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.4680.2017071816404009541\n",
      "\n",
      "FFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.1828.2017032116054257557\n",
      "OFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.4680.2017071816404006533\n",
      "\n",
      "FFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.1828.2017032116054258562\n",
      "OFP: (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.4680.2017071816404009538\n",
      "\n",
      "FFP: (0010, 1030) Patient's Weight                    DS: '65.0'\n",
      "OFP: (0010, 1030) Patient's Weight                    DS: '64.0'\n",
      "\n",
      "FFP: (0018, 0080) Repetition Time                     DS: '702.870971679687'\n",
      "OFP: (0018, 0080) Repetition Time                     DS: '632.583923339843'\n",
      "\n",
      "FFP: (0018, 0084) Imaging Frequency                   DS: '127.763209'\n",
      "OFP: (0018, 0084) Imaging Frequency                   DS: '127.762929'\n",
      "\n",
      "FFP: (0018, 1020) Software Versions                   LO: ['5.3.0', '5.3.0.2']\n",
      "OFP: (0018, 1020) Software Versions                   LO: ['5.3.0', '5.3.0.3']\n",
      "\n",
      "FFP: (0018, 1316) SAR                                 DS: '1.97129201889038'\n",
      "OFP: (0018, 1316) SAR                                 DS: '1.95607185363769'\n",
      "\n",
      "FFP: (0018, 1318) dB/dt                               DS: '80.8085250854492'\n",
      "OFP: (0018, 1318) dB/dt                               DS: '81.0862731933593'\n",
      "\n",
      "FFP: (0018, 9073) Acquisition Duration                FD: 231.94741821289062\n",
      "OFP: (0018, 9073) Acquisition Duration                FD: 243.54481506347656\n",
      "\n",
      "FFP: (0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.23849.23212228212228292729\n",
      "OFP: (0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.23849.23212228212525212126\n",
      "\n",
      "FFP: (0020, 000e) Series Instance UID                 UI: 1.3.46.670589.11.71641.5.0.1828.2017032116071393583\n",
      "OFP: (0020, 000e) Series Instance UID                 UI: 1.3.46.670589.11.71641.5.0.4680.2017071816425367559\n",
      "\n",
      "FFP: (0020, 0010) Study ID                            SH: '537984258'\n",
      "OFP: (0020, 0010) Study ID                            SH: '537723551'\n",
      "\n",
      "FFP: (0020, 0013) Instance Number                     IS: '60'\n",
      "OFP: (0020, 0013) Instance Number                     IS: '56'\n",
      "\n",
      "FFP: (0020, 0032) Image Position (Patient)            DS: [-168.25151556318, -118.42232203483, 105.726453141914]\n",
      "OFP: (0020, 0032) Image Position (Patient)            DS: [-169.04140022347, -140.06561541557, 104.607093810501]\n",
      "\n",
      "FFP: (0020, 0037) Image Orientation (Patient)         DS: [0.99999564886093, 0, -0.0029566788580, 0, 1, 0]\n",
      "OFP: (0020, 0037) Image Orientation (Patient)         DS: [0.99997270107269, 0, 0.00739033799618, 0, 1, 0]\n",
      "\n",
      "FFP: (0020, 0052) Frame of Reference UID              UI: 1.3.46.670589.11.71641.5.0.4524.2017032116034591003\n",
      "OFP: (0020, 0052) Frame of Reference UID              UI: 1.3.46.670589.11.71641.5.0.9344.2017071816381109020\n",
      "\n",
      "FFP: (0020, 1041) Slice Location                      DS: '-105.22852532422'\n",
      "OFP: (0020, 1041) Slice Location                      DS: '-105.85351017424'\n",
      "\n",
      "FFP: (0028, 1053) Rescale Slope                       DS: '4.07619047619047'\n",
      "OFP: (0028, 1053) Rescale Slope                       DS: '5.18876678876678'\n",
      "\n",
      "FFP: (0040, 0244) Performed Procedure Step Start Date DA: '20170321'\n",
      "OFP: (0040, 0244) Performed Procedure Step Start Date DA: '20170718'\n",
      "\n",
      "FFP: (0040, 0245) Performed Procedure Step Start Time TM: '160418'\n",
      "OFP: (0040, 0245) Performed Procedure Step Start Time TM: '163911'\n",
      "\n",
      "FFP: (0040, 0250) Performed Procedure Step End Date   DA: '20170321'\n",
      "OFP: (0040, 0250) Performed Procedure Step End Date   DA: '20170718'\n",
      "\n",
      "FFP: (0040, 0251) Performed Procedure Step End Time   TM: '160418'\n",
      "OFP: (0040, 0251) Performed Procedure Step End Time   TM: '163911'\n",
      "\n",
      "FFP: (0040, 0253) Performed Procedure Step ID         SH: '537984258'\n",
      "OFP: (0040, 0253) Performed Procedure Step ID         SH: '537723551'\n",
      "\n",
      "FFP: (0040, 0275) Request Attributes Sequence         SQ: <Sequence, length 1>\n",
      "OFP: (0040, 0275) Request Attributes Sequence         SQ: <Sequence, length 1>\n",
      "\n",
      "FFP: (0008, 0050) Accession Number                    SH: '2017017868'\n",
      "OFP: (0008, 0050) Accession Number                    SH: '2017044005'\n",
      "\n",
      "FFP: (0040, 0009) Scheduled Procedure Step ID         SH: '2017017868'\n",
      "OFP: (0040, 0009) Scheduled Procedure Step ID         SH: '2017044005'\n",
      "\n",
      "FFP: (0040, 1001) Requested Procedure ID              SH: '2017017868'\n",
      "OFP: (0040, 1001) Requested Procedure ID              SH: '2017044005'\n",
      "\n",
      "FFP: (0040, 1001) Requested Procedure ID              SH: '2017017868'\n",
      "OFP: (0040, 1001) Requested Procedure ID              SH: '2017044005'\n",
      "\n",
      "FFP: (0040, 2004) Issue Date of Imaging Service Reque DA: '20170321'\n",
      "OFP: (0040, 2004) Issue Date of Imaging Service Reque DA: '20170718'\n",
      "\n",
      "FFP: (0040, 2005) Issue Time of Imaging Service Reque TM: '160418.380'\n",
      "OFP: (0040, 2005) Issue Time of Imaging Service Reque TM: '163911.881'\n",
      "\n",
      "FFP: (2001, 100a) [Slice Number MR]                   IS: '60'\n",
      "OFP: (2001, 100a) [Slice Number MR]                   IS: '56'\n",
      "\n",
      "FFP: (2001, 1018) [Number of Slices MR]               SL: 60\n",
      "OFP: (2001, 1018) [Number of Slices MR]               SL: 63\n",
      "\n",
      "FFP: (2001, 1022) [Water Fat Shift]                   FL: 0.9965006113052368\n",
      "OFP: (2001, 1022) [Water Fat Shift]                   FL: 0.9964996576309204\n",
      "\n",
      "FFP: (2001, 105f) [Stack Sequence]                    SQ: <Sequence, length 1>\n",
      "OFP: (2001, 105f) [Stack Sequence]                    SQ: <Sequence, length 1>\n",
      "\n",
      "FFP: (2001, 102d) [Number of Stack Slices]            SS: 60\n",
      "OFP: (2001, 102d) [Number of Stack Slices]            SS: 63\n",
      "\n",
      "FFP: (2005, 1071) [Unknown]                           FL: 0.16940546035766602\n",
      "OFP: (2005, 1071) [Unknown]                           FL: -0.42343902587890625\n",
      "\n",
      "FFP: (2005, 1075) [Unknown]                           FL: 180.0\n",
      "OFP: (2005, 1075) [Unknown]                           FL: 189.0\n",
      "\n",
      "FFP: (2005, 1078) [Unknown]                           FL: 50.90739059448242\n",
      "OFP: (2005, 1078) [Unknown]                           FL: 29.264097213745117\n",
      "\n",
      "FFP: (2005, 1079) [Unknown]                           FL: 16.72618865966797\n",
      "OFP: (2005, 1079) [Unknown]                           FL: 33.86046600341797\n",
      "\n",
      "FFP: (2005, 143c) [Unknown]                           FL: -17.200000762939453\n",
      "OFP: (2005, 143c) [Unknown]                           FL: -34.20000076293945\n",
      "\n",
      "FFP: (2001, 1083) [Imaging Frequency]                 DS: '127.763209'\n",
      "OFP: (2001, 1083) [Imaging Frequency]                 DS: '127.762929'\n",
      "\n",
      "FFP: (2005, 1000) [Unknown]                           FL: 0.16940546035766602\n",
      "OFP: (2005, 1000) [Unknown]                           FL: -0.42343902587890625\n",
      "\n",
      "FFP: (2005, 1008) [Unknown]                           FL: 50.90739059448242\n",
      "OFP: (2005, 1008) [Unknown]                           FL: 29.264097213745117\n",
      "\n",
      "FFP: (2005, 1009) [Unknown]                           FL: 105.22579956054688\n",
      "OFP: (2005, 1009) [Unknown]                           FL: 105.8584976196289\n",
      "\n",
      "FFP: (2005, 100a) [Unknown]                           FL: 1.0774602890014648\n",
      "OFP: (2005, 100a) [Unknown]                           FL: 0.2836898863315582\n",
      "\n",
      "FFP: (2005, 100b) [Unknown]                           FL: 2016.2540283203125\n",
      "OFP: (2005, 100b) [Unknown]                           FL: 1802.69384765625\n",
      "\n",
      "FFP: (2005, 100e) [Unknown]                           FL: 0.2659429609775543\n",
      "OFP: (2005, 100e) [Unknown]                           FL: 0.26158639788627625\n",
      "\n",
      "FFP: (2005, 102a) [Unknown]                           IS: '556301035'\n",
      "OFP: (2005, 102a) [Unknown]                           IS: '566757501'\n",
      "\n",
      "FFP: (2005, 1030) [Repetition Time]                   FL: [702.8709716796875, 0.0]\n",
      "OFP: (2005, 1030) [Repetition Time]                   FL: [632.5839233398438, 0.0]\n",
      "\n",
      "FFP: (2005, 1033) [Acquisition Duration]              FL: 231.94741821289062\n",
      "OFP: (2005, 1033) [Acquisition Duration]              FL: 243.54481506347656\n",
      "\n",
      "FFP: (2005, 140a) [Unknown]                           DS: '4.07619047619047'\n",
      "OFP: (2005, 140a) [Unknown]                           DS: '5.18876678876678'\n",
      "\n",
      "FFP: (2005, 140f) [Unknown]                           SQ: <Sequence, length 1>\n",
      "OFP: (2005, 140f) [Unknown]                           SQ: <Sequence, length 1>\n",
      "\n",
      "FFP: (0008, 002a) Acquisition DateTime                DT: '20170321'\n",
      "OFP: (0008, 002a) Acquisition DateTime                DT: '20170718'\n",
      "\n",
      "FFP: (0018, 9181) Specific Absorption Rate Value      FD: 1.9712920188903809\n",
      "OFP: (0018, 9181) Specific Absorption Rate Value      FD: 1.9560718536376953\n",
      "\n",
      "FFP: (0018, 9182) Gradient Output                     FD: 80.80852508544922\n",
      "OFP: (0018, 9182) Gradient Output                     FD: 81.08627319335938\n",
      "\n",
      "FFP: (2005, 142b) [Unknown]                           CS: 'INITIAL'\n",
      "OFP: (2005, 142b) [Unknown]                           CS: 'PARTLY_ACCEPTED'\n",
      "\n",
      "FFP: (2005, 1442) [Unknown]                           FL: 1.9798812866210938\n",
      "OFP: (2005, 1442) [Unknown]                           FL: 1.9798811674118042\n",
      "\n",
      "FFP: (2005, 1492) Private tag data                    FL: 0.45723608136177063\n",
      "OFP: (2005, 1492) Private tag data                    FL: 0.47639113664627075\n",
      "\n",
      "FFP: (7fe0, 0010) Pixel Data                          OW: Array of 1036800 elements\n",
      "OFP: (7fe0, 0010) Pixel Data                          OW: Array of 1036800 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FFP vs OFP Comparison\n",
    "ffp_list = os.listdir(f'FFP/ID{patient_id}'); ofp_list = os.listdir(f'OFP/ID{patient_id}')\n",
    "ffp_filepath = f\"FFP/ID{patient_id}/{ffp_list[num_slice]}\"\n",
    "ofp_filepath = f\"OFP/ID{patient_id}/{ofp_list[num_slice]}\"\n",
    "ffp_data = pydicom.dcmread(ffp_filepath); ofp_data = pydicom.dcmread(ofp_filepath)\n",
    "#ffp_pixel = ffp_data.pixel_array; ofp_pixel = ofp_data.pixel_array\n",
    "print(f\"Patient Positoning: {str(ffp_data[0x0018, 0x5100].value)} ; {str(ofp_data[0x0018, 0x5100].value)}\\n\\n\" +\\\n",
    "                            \"-------------------------------------------------------------------------\\n\")\n",
    "for ffp, ofp in zip(ffp_data.iterall(), ofp_data.iterall()):\n",
    "    if ffp != ofp: print(f\"FFP: {ffp}\\nOFP: {ofp}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *MRI* **Visualiser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Visualizer\n",
    "def mri_visualizer(\n",
    "    num_slice: int = 0\n",
    "):\n",
    "\n",
    "    # Figure Initialization\n",
    "    figure = plt.figure(figsize = (10, 10))\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.imshow(meta_data['cnt3dYXZ'][:, :, num_slice])#, cmap = meta_data['cmap'])\n",
    "\n",
    "slice_slider = IntSlider(value = 0, min = 0,\n",
    "    max = meta_data['cnt3dYXZ'].shape[2] - 1,\n",
    "    description = 'Slice', continuous_update = False)\n",
    "interactive(mri_visualizer, num_slice = slice_slider)\n",
    "mri_visualizer(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b9acde1b2542d9958b52d0f560bf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Slice', max=59), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single Image Visualizer\n",
    "def mri_visualizer(\n",
    "    num_slice: int = 0\n",
    "):\n",
    "\n",
    "    # Slice File Access\n",
    "    slice_filepath = f\"{patient_pos}/ID{patient_id}/{slice_list[num_slice]}\"\n",
    "    slice_data = pydicom.dcmread(slice_filepath)\n",
    "    pixel_data = slice_data.pixel_array\n",
    "    \n",
    "    # Figure Initialization\n",
    "    figure = plt.figure(figsize = (5, 5))\n",
    "    plt.title(f\"{str(slice_data[0x0018, 0x5100].value)} Position | \" +\\\n",
    "              f\"Slice #{int(slice_data[0x0020, 0x0013].value)} \" +\\\n",
    "              f\"out of {int(len(slice_list))}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.imshow(pixel_data, cmap = plt.cm.binary)\n",
    "\n",
    "# Raw Data Access\n",
    "slice_list = os.listdir(f'{patient_pos}/ID{patient_id}')\n",
    "data_filepath = f\"{patient_pos}/ID{patient_id}/{slice_list[0]}\"\n",
    "raw_data = pydicom.dcmread(data_filepath)\n",
    "    \n",
    "# Slice Visualizer Initialization\n",
    "slice_slider = IntSlider(value = 0, min = 0,\n",
    "    max = int(len(slice_list) - 1),\n",
    "    description = 'Slice', continuous_update = True)\n",
    "interactive(mri_visualizer, num_slice = slice_slider)\n",
    "#mri_visualizer(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004ea7dc71cb4754bf5e68b52124a912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Slice', max=59), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dual Image Visualizer\n",
    "def mri_visualizer(\n",
    "    num_slice: int = 0\n",
    "):\n",
    "\n",
    "    # Slice File Access\n",
    "    ffp_filepath = f\"FFP/ID{patient_id}/{ffp_list[num_slice]}\"\n",
    "    ofp_filepath = f\"OFP/ID{patient_id}/{ofp_list[num_slice]}\"\n",
    "    ffp_data = pydicom.dcmread(ffp_filepath)\n",
    "    ofp_data = pydicom.dcmread(ofp_filepath)\n",
    "    ffp_pixel = ffp_data.pixel_array; ofp_pixel = ofp_data.pixel_array\n",
    "    \n",
    "    # Figure Initialization\n",
    "    figure = plt.figure(figsize = (10, 5))\n",
    "    plt.title(f\"FFP | Slice #{int(ffp_data[0x2001, 0x100a].value)} \" +\\\n",
    "              f\"out of {int(ffp_data[0x2001, 0x1018].value)}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.subplot(1, 2, 1, title =    f\"FFP | Slice #{int(ffp_data[0x2001, 0x100a].value)} \" +\\\n",
    "                                    f\"out of {int(ffp_data[0x2001, 0x1018].value)}\")\n",
    "    plt.imshow(ffp_pixel, cmap = plt.cm.binary)\n",
    "    plt.subplot(1, 2, 2, title =    f\"OFP | Slice #{int(ofp_data[0x2001, 0x100a].value)} \" +\\\n",
    "                                    f\"out of {int(ofp_data[0x2001, 0x1018].value)}\")\n",
    "    plt.imshow(ofp_pixel, cmap = plt.cm.binary)\n",
    "\n",
    "# Raw Data Access\n",
    "ffp_list = os.listdir(f'FFP/ID{patient_id}')\n",
    "ofp_list = os.listdir(f'OFP/ID{patient_id}')\n",
    "data_filepath = f\"{patient_pos}/ID{patient_id}/{ffp_list[0]}\"\n",
    "raw_data = pydicom.dcmread(data_filepath)\n",
    "    \n",
    "# Slice Visualizer Initialization\n",
    "slice_slider = IntSlider(value = 0, min = 0,\n",
    "    max = int(raw_data[0x2001, 0x1018].value - 1),\n",
    "    description = 'Slice', continuous_update = True)\n",
    "interactive(mri_visualizer, num_slice = slice_slider)\n",
    "#mri_visualizer(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Dataset* **Reader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional MetaBrest Dataset Reader Class (V0)\n",
    "class NCDataset(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        dataset: str = 'private',\n",
    "        mode: str = 'train',\n",
    "    ):  \n",
    "        \n",
    "        # Dataset Choice\n",
    "        super(NCDataset).__init__(); self.settings = settings\n",
    "        self.mode = mode; self.dataset = dataset\n",
    "        if self.dataset == 'public': self.data_folderpath = self.settings.public_data_folderpath\n",
    "        elif self.dataset == 'private': self.data_folderpath = self.settings.private_data_folderpath\n",
    "        else: print(\"ERROR: Chosen Dataset / Directory does not exist!\")\n",
    "        \n",
    "        # Subject Indexing (Existing or New Version)\n",
    "        subj_listpath = Path(f\"{self.settings.data_reader_folderpath}/V{self.settings.data_version}\" +\\\n",
    "                             f\"/{self.dataset}_{self.mode}_setV{self.settings.data_version}.txt\")\n",
    "        if subj_listpath.exists():\n",
    "            print(f\"Reading {self.dataset} Dataset Save Files for {self.mode} Set | Version {settings.data_version}\")\n",
    "            self.subj_list = subj_listpath.read_text().splitlines()\n",
    "        else:\n",
    "            print(f\"Generating New Save Files for {self.dataset} Dataset | Version {settings.data_version}\")\n",
    "            self.subj_list = os.listdir(self.data_folderpath)       # Complete List of Subjects in Dataset\n",
    "\n",
    "            self.subj_list = self.subj_split(self.subj_list)        # Selected List of Subjects in Dataset\n",
    "        #assert len(self.subj_list) == self.num_subj, f\"WARNING: Number of subjs does not match Dataset Version!\"\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Dataset Transformations Initialization\n",
    "        self.transform = transforms.Compose([   transforms.Resize(( self.settings.img_size,\n",
    "                                                            self.settings.img_size)),\n",
    "                                                transforms.ToTensor()])\n",
    "        self.h_flip = transforms.Compose([      transforms.RandomHorizontalFlip(p = 1)])\n",
    "        self.v_flip = transforms.Compose([      transforms.RandomVerticalFlip(p = 1)])\n",
    "\n",
    "    # ============================================================================================\n",
    "\n",
    "    # DataLoader Length / No. Subjects Computation Functionality\n",
    "    def __len__(self): len(self.subj_list)\n",
    "    \n",
    "    # Subject Splitting Functionality\n",
    "    def subj_split(self, subj_list: list):\n",
    "\n",
    "        # Dataset Splitting\n",
    "        assert 0 < (self.settings.train_subj + self.settings.val_subj + self.settings.test_subj) <= len(subj_list),\\\n",
    "               f\"ERROR: Dataset does not contain {self.settings.train_subj + self.settings.val_subj + self.settings.test_subj} Subjects!\"\n",
    "        train_subj = np.sort(np.array(random.sample(subj_list, self.settings.train_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in train_subj]                                  # Training Set Splitting\n",
    "        val_subj = np.sort(np.array(random.sample(subj_list, self.settings.val_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in val_subj]                                    # Validation Set Splitting\n",
    "        test_subj = np.sort(np.array(random.sample(subj_list, self.settings.test_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in test_subj]                                   # Test Set Splitting\n",
    "        subj_list = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        assert len(subj_list) + self.settings.train_subj + self.settings.val_subj + self.settings.test_subj == len(self.subj_list),\\\n",
    "               f\"ERROR: Dataset Splitting went Wrong!\"\n",
    "\n",
    "        # Dataset Split Saving\n",
    "        if not os.path.isdir(f\"V{self.settings.data_version}\"): os.mkdir(f\"V{self.settings.data_version}\")\n",
    "        if len(train_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_train_setV{self.settings.data_version}.txt\", train_subj, fmt='%s')\n",
    "        if len(val_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_val_setV{self.settings.data_version}.txt\", val_subj, fmt='%s')\n",
    "        if len(test_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_test_setV{self.settings.data_version}.txt\", test_subj, fmt='%s')\n",
    "        if len(subj_list) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_rest_set (V{self.settings.data_version}).txt\", subj_list, fmt='%s')\n",
    "        \n",
    "    # ============================================================================================\n",
    "        \n",
    "    # Single Batch / Subject Generation Functionality\n",
    "    def __getitem__(self, idx: int = 0 or str):\n",
    "        \n",
    "        # Subject Folder Access\n",
    "        subj_idx = idx if type(idx) == str else self.subj_list[idx]\n",
    "        subj_folderpath = f\"{self.data_folderpath}/{subj_idx}\"\n",
    "        subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while len(subj_filelist) > 0 and len(subj_filelist) <= 3:\n",
    "            subj_folderpath = Path(f\"{subj_folderpath}/{subj_filelist[0]}\")\n",
    "            subj_filelist = os.listdir(subj_folderpath)\n",
    "        \n",
    "        while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "\n",
    "        # Subject General Information Access\n",
    "        subj_filepath = Path((f\"{subj_folderpath}/{subj_filelist[i]}\"))\n",
    "        subj_info = pydicom.dcmread(subj_filepath)\n",
    "        subj_id = str(subj_info[0x0010, 0x0010].value)\n",
    "        subj_ori = subj_info[0x0020, 0x0037].value\n",
    "        subj_v_flip = (np.all(subj_ori == [-1, 0, 0, 0, -1, 0]))\n",
    "        subj_h_flip = (torch.rand(1) < (self.settings.h_flip / 100))\n",
    "        num_row = subj_info.Rows; num_col = subj_info.Columns\n",
    "        if self.dataset == 'private':\n",
    "            num_slice = int(subj_info[0x2001, 0x1018].value)\n",
    "            preg_status = int(subj_info[0x0010, 0x21c0].value)\n",
    "        else:\n",
    "            num_slice = int(subj_info[0x0020, 0x1002].value)\n",
    "            preg_status = None\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Subject Slice Data Access\n",
    "        img_data = torch.empty((num_slice, self.settings.img_size, self.settings.img_size))\n",
    "        for slice_filepath in subj_filelist:\n",
    "            if os.path.splitext(slice_filepath)[1] in ['', '.dcm']:\n",
    "                \n",
    "                # Slice Data Access\n",
    "                slice_filepath = Path(f\"{subj_folderpath}/{slice_filepath}\")\n",
    "                slice_data = pydicom.dcmread(slice_filepath, force=True)\n",
    "                slice_idx = int(slice_data[0x0020, 0x0013].value) - 1\n",
    "                img_slice = slice_data.pixel_array.astype(float)\n",
    "\n",
    "                # Slice Image Pre-Processing | Rescaling, Resizing & Flipping\n",
    "                if self.settings.data_prep:\n",
    "                    img_slice = np.uint8((np.maximum(img_slice, 0) / img_slice.max()) * 255)\n",
    "                    img_slice = Image.fromarray(img_slice).resize(( self.settings.img_size,\n",
    "                                                                    self.settings.img_size)) \n",
    "                    if subj_h_flip: img_slice = self.h_flip(img_slice)\n",
    "                    if subj_v_flip: img_slice = self.v_flip(img_slice)\n",
    "                    img_slice = np.array(self.transform(img_slice))\n",
    "                img_data[slice_idx, :, :] = torch.Tensor(img_slice)\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Correction for Chosen Number of Slices\n",
    "        extra_slice = self.settings.num_slice - num_slice\n",
    "        if num_slice < self.settings.num_slice:             # Addition of Repeated Peripheral Slices\n",
    "            for extra in range(extra_slice):\n",
    "                if extra % 2 == 0: img_data = torch.cat((img_data, img_data[-1].unsqueeze(0)), dim = 0)\n",
    "                else: img_data = torch.cat((img_data[0].unsqueeze(0), img_data), dim = 0)\n",
    "        elif num_slice > self.settings.num_slice:           # Removal of Emptier Peripheral Slices\n",
    "            img_data = img_data[int(np.ceil(-extra_slice / 2)) :\\\n",
    "                int(len(img_data) - np.floor(-extra_slice / 2))]\n",
    "        else: assert(num_slice == self.settings.num_slice)\n",
    "          \n",
    "        # Item Dictionary Returning\n",
    "        return {'img_data': img_data,#.unsqueeze(0),\n",
    "                'resolution': f'[{num_row}, {num_col}]',\n",
    "                'subj_id': subj_id, 'num_slice': num_slice,\n",
    "                'preg_status': preg_status, 'orientation': subj_ori,\n",
    "                'h_flip': subj_h_flip, 'v_flip': subj_v_flip,\n",
    "                'position': str(subj_info[0x0018, 0x5100].value),\n",
    "                'num_series': int(subj_info.SeriesNumber)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional MetaBrest Dataset Reader Class (V1)\n",
    "class NCDataset(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        dataset: str = 'private',\n",
    "        mode: str = 'train',\n",
    "    ):  \n",
    "        \n",
    "        # Dataset Choice\n",
    "        super(NCDataset).__init__(); self.settings = settings\n",
    "        self.mode = mode; self.dataset = dataset\n",
    "        if self.dataset == 'public': self.data_folderpath = self.settings.public_data_folderpath\n",
    "        elif self.dataset == 'private': self.data_folderpath = self.settings.private_data_folderpath\n",
    "        else: print(\"ERROR: Chosen Dataset / Directory does not exist!\")\n",
    "        \n",
    "        # Subject Indexing (Existing or New Version)\n",
    "        subj_listpath = Path(f\"{self.settings.reader_folderpath}/V{self.settings.data_version}\" +\\\n",
    "                             f\"/{self.dataset}_{self.mode}_setV{self.settings.data_version}.txt\")\n",
    "        if subj_listpath.exists():\n",
    "            print(f\"Reading {self.dataset} Dataset Save Files for {self.mode} Set | Version {settings.data_version}\")\n",
    "            self.subj_list = subj_listpath.read_text().splitlines()\n",
    "        else:\n",
    "            print(f\"Generating New Save Files for {self.dataset} Dataset | Version {settings.data_version}\")\n",
    "            self.subj_list = os.listdir(self.data_folderpath)       # Complete List of Subjects in Dataset\n",
    "            self.subj_list = self.subj_split(self.subj_list)        # Selected List of Subjects in Dataset\n",
    "        #assert len(self.subj_list) == self.num_subj, f\"WARNING: Number of subjs does not match Dataset Version!\"\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Dataset Transformations Initialization\n",
    "        self.transform = transforms.Compose([\n",
    "                                        transforms.Resize(( self.settings.img_size,\n",
    "                                                            self.settings.img_size)),\n",
    "                                        transforms.ToTensor()])\n",
    "        self.h_flip = transforms.Compose([transforms.RandomHorizontalFlip(p = 1)])\n",
    "        self.v_flip = transforms.Compose([transforms.RandomVerticalFlip(p = 1)])\n",
    "\n",
    "    # ============================================================================================\n",
    "\n",
    "    # DataLoader Length / No. Subjects Computation Functionality\n",
    "    def __len__(self): return len(self.subj_list)\n",
    "    \n",
    "    # Subject Splitting Functionality\n",
    "    def subj_split(self, subj_list: list):\n",
    "\n",
    "        # Dataset Splitting\n",
    "        assert 0 < (self.settings.train_subj + self.settings.val_subj + self.settings.test_subj) <= len(subj_list),\\\n",
    "               f\"ERROR: Dataset does not contain {self.settings.train_subj + self.settings.val_subj + self.settings.test_subj} Subjects!\"\n",
    "        if self.settings.train_subj != 0:\n",
    "            train_subj = np.sort(np.array(random.sample(subj_list, self.settings.train_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in train_subj]                                  # Training Set Splitting\n",
    "            val_subj = np.sort(np.array(random.sample(subj_list, self.settings.val_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in val_subj]                                    # Validation Set Splitting\n",
    "            test_subj = np.sort(np.array(random.sample(subj_list, self.settings.test_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in test_subj]                                   # Test Set Splitting\n",
    "            subj_list = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        else: train_subj = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        assert len(subj_list) + self.settings.train_subj + self.settings.val_subj + self.settings.test_subj == len(self.subj_list),\\\n",
    "                                                                                            f\"ERROR: Dataset Splitting went Wrong!\"\n",
    "\n",
    "        # Dataset Split Saving\n",
    "        if not os.path.isdir(f\"V{self.settings.data_version}\"): os.mkdir(f\"V{self.settings.data_version}\")\n",
    "        if len(train_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_train_setV{self.settings.data_version}.txt\", train_subj, fmt='%s')\n",
    "        if len(val_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_val_setV{self.settings.data_version}.txt\", val_subj, fmt='%s')\n",
    "        if len(test_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_test_setV{self.settings.data_version}.txt\", test_subj, fmt='%s')\n",
    "        if len(subj_list) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_rest_set (V{self.settings.data_version}).txt\", subj_list, fmt='%s')\n",
    "        \n",
    "    # ============================================================================================\n",
    "        \n",
    "    # Single Batch / Subject Generation Functionality\n",
    "    def __getitem__(self, idx: int = 0 or str):\n",
    "        \n",
    "        # Subject Folder Access\n",
    "        subj_idx = idx if type(idx) == str else self.subj_list[idx]\n",
    "        subj_folderpath = f\"{self.data_folderpath}/{subj_idx}\"\n",
    "        subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while len(subj_filelist) > 0 and len(subj_filelist) <= 3:\n",
    "            while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "            subj_folderpath = Path(f\"{subj_folderpath}/{subj_filelist[i]}\")\n",
    "            subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "\n",
    "        # Subject General Information Access\n",
    "        #print(f\"Accessing Subject {subj_idx}: {len(subj_filelist) - i} Slices\")\n",
    "        subj_filepath = Path((f\"{subj_folderpath}/{subj_filelist[i]}\"))\n",
    "        subj_info = pydicom.dcmread(subj_filepath)\n",
    "        subj_ori = subj_info[0x0020, 0x0037].value\n",
    "        subj_v_flip = (np.all(subj_ori == [-1, 0, 0, 0, -1, 0]))\n",
    "        subj_h_flip = (torch.rand(1) < (self.settings.h_flip / 100))\n",
    "        #num_row = subj_info.Rows; num_col = subj_info.Columns\n",
    "        #if self.dataset == 'private':\n",
    "            #num_slice = int(subj_info[0x2001, 0x1018].value)\n",
    "            #preg_status = int(subj_info[0x0010, 0x21c0].value)\n",
    "        #else:\n",
    "            #num_slice = int(subj_info[0x0020, 0x1002].value)\n",
    "            #preg_status = None\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Subject Slice Data Access\n",
    "        img_data = torch.empty((70, self.settings.img_size, self.settings.img_size)); slice_list = []\n",
    "        for slice_filepath in subj_filelist:\n",
    "            if os.path.splitext(slice_filepath)[1] in ['', '.dcm']:\n",
    "                \n",
    "                # Slice Data Access\n",
    "                slice_filepath = Path(f\"{subj_folderpath}/{slice_filepath}\")\n",
    "                slice_data = pydicom.dcmread(slice_filepath, force=True)\n",
    "                slice_idx = int(slice_data[0x0020, 0x0013].value) - 1\n",
    "                slice_list.append(slice_idx)\n",
    "                img_slice = slice_data.pixel_array.astype(float)\n",
    "\n",
    "                # Slice Image Pre-Processing | Rescaling, Resizing & Flipping\n",
    "                if self.settings.data_prep:\n",
    "                    img_slice = np.uint8((np.maximum(img_slice, 0) / img_slice.max()) * 255)\n",
    "                    img_slice = Image.fromarray(img_slice).resize(( self.settings.img_size,\n",
    "                                                                    self.settings.img_size)) \n",
    "                    if subj_h_flip: img_slice = self.h_flip(img_slice)\n",
    "                    if subj_v_flip: img_slice = self.v_flip(img_slice)\n",
    "                    img_slice = np.array(self.transform(img_slice))\n",
    "                img_data[slice_idx, :, :] = torch.Tensor(img_slice); del img_slice\n",
    "        img_data = img_data[np.sort(slice_list)]\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Correction for Chosen Number of Slices\n",
    "        extra_slice = self.settings.num_slice - img_data.shape[0]\n",
    "        if img_data.shape[0] < self.settings.num_slice:             # Addition of Repeated Peripheral Slices\n",
    "            for extra in range(extra_slice):\n",
    "                if extra % 2 == 0: img_data = torch.cat((img_data, img_data[-1].unsqueeze(0)), dim = 0)\n",
    "                else: img_data = torch.cat((img_data[0].unsqueeze(0), img_data), dim = 0)\n",
    "        elif img_data.shape[0] > self.settings.num_slice:           # Removal of Emptier Peripheral Slices\n",
    "            img_data = img_data[int(np.ceil(-extra_slice / 2)) :\\\n",
    "                int(len(img_data) - np.floor(-extra_slice / 2))]\n",
    "        #else: assert(num_slice == self.settings.num_slice)\n",
    "          \n",
    "        # Item Dictionary Returning\n",
    "        return img_data.unsqueeze(0)\n",
    "        \"\"\"return {'img_data': img_data,#.unsqueeze(0),\n",
    "                'resolution': f'[{num_row}, {num_col}]',\n",
    "                'subj_id': subj_id, 'num_slice': num_slice,\n",
    "                'preg_status': preg_status, 'orientation': subj_ori,\n",
    "                'h_flip': subj_h_flip, 'v_flip': subj_v_flip,\n",
    "                'position': str(subj_info[0x0018, 0x5100].value),\n",
    "                'num_series': int(subj_info.SeriesNumber)}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional MetaBrest Dataset Reader Class (V2)\n",
    "class NCDataset(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        dataset: str = 'private',\n",
    "        mode: str = 'train',\n",
    "    ):  \n",
    "        \n",
    "        # Dataset Choice\n",
    "        super(NCDataset).__init__(); self.settings = settings\n",
    "        self.mode = mode; self.dataset = dataset\n",
    "        if self.dataset == 'public': self.data_folderpath = self.settings.public_data_folderpath\n",
    "        elif self.dataset == 'private': self.data_folderpath = self.settings.private_data_folderpath\n",
    "        else: print(\"ERROR: Chosen Dataset / Directory does not exist!\")\n",
    "        \n",
    "        # Subject Indexing (Existing or New Version)\n",
    "        subj_listpath = Path(f\"{self.settings.reader_folderpath}/V{self.settings.data_version}\" +\\\n",
    "                             f\"/{self.dataset}_{self.mode}_setV{self.settings.data_version}.txt\")\n",
    "        if subj_listpath.exists():\n",
    "            print(f\"Reading {self.dataset} Dataset Save Files for {self.mode} Set | Version {settings.data_version}\")\n",
    "            self.subj_list = subj_listpath.read_text().splitlines()\n",
    "        else:\n",
    "            print(f\"Generating New Save Files for {self.dataset} Dataset | Version {settings.data_version}\")\n",
    "            self.subj_list = os.listdir(self.data_folderpath)       # Complete List of Subjects in Dataset\n",
    "            self.subj_list = self.subj_split(self.subj_list)        # Selected List of Subjects in Dataset\n",
    "        #assert len(self.subj_list) == self.num_subj, f\"WARNING: Number of subjs does not match Dataset Version!\"\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Dataset Transformations Initialization\n",
    "        self.transform = transforms.Compose([\n",
    "                                        transforms.Resize(( self.settings.img_size,\n",
    "                                                            self.settings.img_size)),\n",
    "                                        transforms.ToTensor()])\n",
    "        self.h_flip = transforms.Compose([transforms.RandomHorizontalFlip(p = 1)])\n",
    "        self.v_flip = transforms.Compose([transforms.RandomVerticalFlip(p = 1)])\n",
    "\n",
    "    # ============================================================================================\n",
    "\n",
    "    # DataLoader Length / No. Subjects Computation Functionality\n",
    "    def __len__(self): return len(self.subj_list)\n",
    "    \n",
    "    # Subject Splitting Functionality\n",
    "    def subj_split(self, subj_list: list):\n",
    "\n",
    "        # Dataset Splitting\n",
    "        train_subj = len(subj_list) if self.settings.train_subj == 0 else self.settings.train_subj\n",
    "        assert 0 < (train_subj + self.settings.val_subj + self.settings.test_subj) <= len(subj_list),\\\n",
    "               f\"ERROR: Dataset does not contain {train_subj + self.settings.val_subj + self.settings.test_subj} Subjects!\"\n",
    "        train_subj = np.sort(np.array(random.sample(subj_list, train_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in train_subj]                                      # Training Set Splitting\n",
    "        if self.settings.train_subj != 0:\n",
    "            val_subj = np.sort(np.array(random.sample(subj_list, self.settings.val_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in val_subj]                                    # Validation Set Splitting\n",
    "            test_subj = np.sort(np.array(random.sample(subj_list, self.settings.test_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in test_subj]                                   # Test Set Splitting\n",
    "            subj_list = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        assert len(subj_list) + len(train_subj) + self.settings.val_subj + self.settings.test_subj == len(self.subj_list),\\\n",
    "               f\"ERROR: Dataset Splitting went Wrong!\"\n",
    "\n",
    "        # Dataset Split Saving\n",
    "        if not os.path.isdir(f\"V{self.settings.data_version}\"): os.mkdir(f\"V{self.settings.data_version}\")\n",
    "        if len(train_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_train_setV{self.settings.data_version}.txt\", train_subj, fmt='%s')\n",
    "        if len(subj_list) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_rest_set (V{self.settings.data_version}).txt\", subj_list, fmt='%s')\n",
    "        if self.settings.train_subj != 0:\n",
    "            if len(val_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_val_setV{self.settings.data_version}.txt\", val_subj, fmt='%s')\n",
    "            if len(test_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_test_setV{self.settings.data_version}.txt\", test_subj, fmt='%s')\n",
    "        \n",
    "    # ============================================================================================\n",
    "        \n",
    "    # Single Batch / Subject Generation Functionality\n",
    "    def __getitem__(self, idx: int = 0 or str):\n",
    "        \n",
    "        # Subject Folder Access\n",
    "        subj_idx = idx if type(idx) == str else self.subj_list[idx]\n",
    "        subj_folderpath = f\"{self.data_folderpath}/{subj_idx}\"\n",
    "        subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while len(subj_filelist) > 0 and len(subj_filelist) <= 3:\n",
    "            subj_folderpath = Path(f\"{subj_folderpath}/{subj_filelist[0]}\")\n",
    "            subj_filelist = os.listdir(subj_folderpath)\n",
    "        while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "\n",
    "        # Subject General Information Access\n",
    "        #print(f\"Accessing Subject {subj_idx}: {len(subj_filelist) - i} Slices\")\n",
    "        subj_filepath = Path((f\"{subj_folderpath}/{subj_filelist[i]}\"))\n",
    "        subj_info = pydicom.dcmread(subj_filepath)\n",
    "        subj_ori = subj_info[0x0020, 0x0037].value\n",
    "        subj_v_flip = (np.all(subj_ori == [-1, 0, 0, 0, -1, 0]))\n",
    "        subj_h_flip = (torch.rand(1) < (self.settings.h_flip / 100))\n",
    "        #num_row = subj_info.Rows; num_col = subj_info.Columns\n",
    "        #if self.dataset == 'private':\n",
    "            #num_slice = int(subj_info[0x2001, 0x1018].value)\n",
    "            #preg_status = int(subj_info[0x0010, 0x21c0].value)\n",
    "        #else:\n",
    "            #num_slice = int(subj_info[0x0020, 0x1002].value)\n",
    "            #preg_status = None\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Subject Slice Data Access\n",
    "        img_data = torch.empty((70, self.settings.img_size, self.settings.img_size)); slice_list = []\n",
    "        for slice_filepath in subj_filelist:\n",
    "            if os.path.splitext(slice_filepath)[1] in ['', '.dcm']:\n",
    "                \n",
    "                # Slice Data Access\n",
    "                slice_filepath = Path(f\"{subj_folderpath}/{slice_filepath}\")\n",
    "                slice_data = pydicom.dcmread(slice_filepath, force=True)\n",
    "                slice_idx = int(slice_data[0x0020, 0x0013].value) - 1\n",
    "                slice_list.append(slice_idx)\n",
    "                img_slice = slice_data.pixel_array.astype(float)\n",
    "\n",
    "                # Slice Image Pre-Processing | Rescaling, Resizing & Flipping\n",
    "                if self.settings.data_prep:\n",
    "                    img_slice = np.uint8((np.maximum(img_slice, 0) / img_slice.max()) * 255)\n",
    "                    img_slice = Image.fromarray(img_slice).resize(( self.settings.img_size,\n",
    "                                                                    self.settings.img_size)) \n",
    "                    if subj_h_flip: img_slice = self.h_flip(img_slice)\n",
    "                    if subj_v_flip: img_slice = self.v_flip(img_slice)\n",
    "                    img_slice = np.array(self.transform(img_slice))\n",
    "                img_data[slice_idx, :, :] = torch.Tensor(img_slice); del img_slice\n",
    "        img_data = img_data[np.sort(slice_list)]\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Correction for Chosen Number of Slices\n",
    "        extra_slice = self.settings.num_slice - img_data.shape[0]\n",
    "        if img_data.shape[0] < self.settings.num_slice:             # Addition of Repeated Peripheral Slices\n",
    "            for extra in range(extra_slice):\n",
    "                if extra % 2 == 0: img_data = torch.cat((img_data, img_data[-1].unsqueeze(0)), dim = 0)\n",
    "                else: img_data = torch.cat((img_data[0].unsqueeze(0), img_data), dim = 0)\n",
    "        elif img_data.shape[0] > self.settings.num_slice:           # Removal of Emptier Peripheral Slices\n",
    "            img_data = img_data[int(np.ceil(-extra_slice / 2)) :\\\n",
    "                int(len(img_data) - np.floor(-extra_slice / 2))]\n",
    "        #else: assert(num_slice == self.settings.num_slice)\n",
    "          \n",
    "        # Item Dictionary Returning\n",
    "        return img_data.unsqueeze(0)\n",
    "        \"\"\"return {'img_data': img_data,#.unsqueeze(0),\n",
    "                'resolution': f'[{num_row}, {num_col}]',\n",
    "                'subj_id': subj_id, 'num_slice': num_slice,\n",
    "                'preg_status': preg_status, 'orientation': subj_ori,\n",
    "                'h_flip': subj_h_flip, 'v_flip': subj_v_flip,\n",
    "                'position': str(subj_info[0x0018, 0x5100].value),\n",
    "                'num_series': int(subj_info.SeriesNumber)}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading public Dataset Save Files for train Set | Version 0\n",
      "torch.Size([1, 30, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Dataset Initialization Example\n",
    "dataset = NCDataset(settings,\n",
    "                    mode = 'train',\n",
    "                    dataset = 'public')\n",
    "data = dataset.__getitem__(0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c89fd3d884ab8b188b3c9c6a7854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Slice', max=30, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single 3D Image Visualizer\n",
    "def mri_visualizer(\n",
    "    num_slice: int = 0\n",
    "):\n",
    "    \n",
    "    # Figure Initialization\n",
    "    figure = plt.figure(figsize = (5, 5)); plt.title(f\"Slice #{num_slice}\")\n",
    "    plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "    plt.imshow(data[0][num_slice - 1], cmap = plt.cm.binary)\n",
    "    \n",
    "# Slice Visualizer Initialization\n",
    "slice_slider = IntSlider(   value = 1, min = 1,\n",
    "                            max = settings.num_slice,\n",
    "    description = 'Slice', continuous_update = True)\n",
    "interactive(mri_visualizer, num_slice = slice_slider)\n",
    "#mri_visualizer(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Dataset* **Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading public Dataset Save Files for train Set | Version 1\n",
      "Reading private Dataset Save Files for train Set | Version 1\n"
     ]
    }
   ],
   "source": [
    "# Non-Conditional MetaBrest Dataset Reader Class (V2)\n",
    "class NCDataset(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        dataset: str = 'private',\n",
    "        mode: str = 'train',\n",
    "    ):  \n",
    "        \n",
    "        # Dataset Choice\n",
    "        super(NCDataset).__init__(); self.settings = settings\n",
    "        self.mode = mode; self.dataset = dataset\n",
    "        if self.dataset == 'public': self.data_folderpath = self.settings.public_data_folderpath\n",
    "        elif self.dataset == 'private': self.data_folderpath = self.settings.private_data_folderpath\n",
    "        else: print(\"ERROR: Chosen Dataset / Directory does not exist!\")\n",
    "        \n",
    "        # Subject Indexing (Existing or New Version)\n",
    "        subj_listpath = Path(f\"{self.settings.reader_folderpath}/V{self.settings.data_version}\" +\\\n",
    "                             f\"/{self.dataset}_{self.mode}_setV{self.settings.data_version}.txt\")\n",
    "        if subj_listpath.exists():\n",
    "            print(f\"Reading {self.dataset} Dataset Save Files for {self.mode} Set | Version {settings.data_version}\")\n",
    "            self.subj_list = subj_listpath.read_text().splitlines()\n",
    "        else:\n",
    "            print(f\"Generating New Save Files for {self.dataset} Dataset | Version {settings.data_version}\")\n",
    "            self.subj_list = os.listdir(self.data_folderpath)       # Complete List of Subjects in Dataset\n",
    "            self.subj_list = self.subj_split(self.subj_list)        # Selected List of Subjects in Dataset\n",
    "        #assert len(self.subj_list) == self.num_subj, f\"WARNING: Number of subjs does not match Dataset Version!\"\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Dataset Transformations Initialization\n",
    "        self.transform = transforms.Compose([\n",
    "                                        transforms.Resize(( self.settings.img_size,\n",
    "                                                            self.settings.img_size)),\n",
    "                                        transforms.ToTensor()])\n",
    "        self.h_flip = transforms.Compose([transforms.RandomHorizontalFlip(p = 1)])\n",
    "        self.v_flip = transforms.Compose([transforms.RandomVerticalFlip(p = 1)])\n",
    "\n",
    "    # ============================================================================================\n",
    "\n",
    "    # DataLoader Length / No. Subjects Computation Functionality\n",
    "    def __len__(self): return len(self.subj_list)\n",
    "    \n",
    "    # Subject Splitting Functionality\n",
    "    def subj_split(self, subj_list: list):\n",
    "\n",
    "        # Dataset Splitting\n",
    "        train_subj = len(subj_list) if self.settings.train_subj == 0 else self.settings.train_subj\n",
    "        assert 0 < (train_subj + self.settings.val_subj + self.settings.test_subj) <= len(subj_list),\\\n",
    "               f\"ERROR: Dataset does not contain {train_subj + self.settings.val_subj + self.settings.test_subj} Subjects!\"\n",
    "        train_subj = np.sort(np.array(random.sample(subj_list, train_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in train_subj]                                      # Training Set Splitting\n",
    "        if self.settings.train_subj != 0:\n",
    "            val_subj = np.sort(np.array(random.sample(subj_list, self.settings.val_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in val_subj]                                    # Validation Set Splitting\n",
    "            test_subj = np.sort(np.array(random.sample(subj_list, self.settings.test_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in test_subj]                                   # Test Set Splitting\n",
    "            subj_list = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        assert len(subj_list) + len(train_subj) + self.settings.val_subj + self.settings.test_subj == len(self.subj_list),\\\n",
    "               f\"ERROR: Dataset Splitting went Wrong!\"\n",
    "\n",
    "        # Dataset Split Saving\n",
    "        if not os.path.isdir(f\"V{self.settings.data_version}\"): os.mkdir(f\"V{self.settings.data_version}\")\n",
    "        if len(train_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_train_setV{self.settings.data_version}.txt\", train_subj, fmt='%s')\n",
    "        if len(subj_list) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_rest_set (V{self.settings.data_version}).txt\", subj_list, fmt='%s')\n",
    "        if self.settings.train_subj != 0:\n",
    "            if len(val_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_val_setV{self.settings.data_version}.txt\", val_subj, fmt='%s')\n",
    "            if len(test_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_test_setV{self.settings.data_version}.txt\", test_subj, fmt='%s')\n",
    "        \n",
    "    # ============================================================================================\n",
    "        \n",
    "    # Single Batch / Subject Generation Functionality\n",
    "    def __getitem__(self, idx: int = 0 or str):\n",
    "        \n",
    "        # Subject Folder Access\n",
    "        subj_idx = idx if type(idx) == str else self.subj_list[idx]\n",
    "        subj_folderpath = f\"{self.data_folderpath}/{subj_idx}\"\n",
    "        subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while len(subj_filelist) > 0 and len(subj_filelist) <= 3:\n",
    "            subj_folderpath = Path(f\"{subj_folderpath}/{subj_filelist[0]}\")\n",
    "            subj_filelist = os.listdir(subj_folderpath)\n",
    "        while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "\n",
    "        # Subject General Information Access\n",
    "        #print(f\"Accessing Subject {subj_idx}: {len(subj_filelist) - i} Slices\")\n",
    "        subj_filepath = Path((f\"{subj_folderpath}/{subj_filelist[i]}\"))\n",
    "        subj_info = pydicom.dcmread(subj_filepath)\n",
    "        subj_ori = subj_info[0x0020, 0x0037].value\n",
    "        subj_v_flip = (np.all(subj_ori == [-1, 0, 0, 0, -1, 0]))\n",
    "        subj_h_flip = (torch.rand(1) < (self.settings.h_flip / 100))\n",
    "        num_row = subj_info.Rows; num_col = subj_info.Columns\n",
    "        if self.dataset == 'private':\n",
    "            num_slice = int(subj_info[0x2001, 0x1018].value)\n",
    "            preg_status = int(subj_info[0x0010, 0x21c0].value)\n",
    "        else:\n",
    "            #num_slice = int(subj_info[0x0020, 0x1002].value)\n",
    "            num_slice = None\n",
    "            preg_status = None\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Subject Slice Data Access\n",
    "        img_data = torch.empty((70, self.settings.img_size, self.settings.img_size)); slice_list = []\n",
    "        for slice_filepath in subj_filelist:\n",
    "            if os.path.splitext(slice_filepath)[1] in ['', '.dcm']:\n",
    "                \n",
    "                # Slice Data Access\n",
    "                slice_filepath = Path(f\"{subj_folderpath}/{slice_filepath}\")\n",
    "                slice_data = pydicom.dcmread(slice_filepath, force=True)\n",
    "                slice_idx = int(slice_data[0x0020, 0x0013].value) - 1\n",
    "                slice_list.append(slice_idx)\n",
    "                img_slice = slice_data.pixel_array.astype(float)\n",
    "\n",
    "                # Slice Image Pre-Processing | Rescaling, Resizing & Flipping\n",
    "                if self.settings.data_prep:\n",
    "                    img_slice = np.uint8((np.maximum(img_slice, 0) / img_slice.max()) * 255)\n",
    "                    img_slice = Image.fromarray(img_slice).resize(( self.settings.img_size,\n",
    "                                                                    self.settings.img_size)) \n",
    "                    if subj_h_flip: img_slice = self.h_flip(img_slice)\n",
    "                    if subj_v_flip: img_slice = self.v_flip(img_slice)\n",
    "                    img_slice = np.array(self.transform(img_slice))\n",
    "                img_data[slice_idx, :, :] = torch.Tensor(img_slice); del img_slice\n",
    "        img_data = img_data[np.sort(slice_list)]\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Correction for Chosen Number of Slices\n",
    "        extra_slice = self.settings.num_slice - img_data.shape[0]\n",
    "        if img_data.shape[0] < self.settings.num_slice:             # Addition of Repeated Peripheral Slices\n",
    "            for extra in range(extra_slice):\n",
    "                if extra % 2 == 0: img_data = torch.cat((img_data, img_data[-1].unsqueeze(0)), dim = 0)\n",
    "                else: img_data = torch.cat((img_data[0].unsqueeze(0), img_data), dim = 0)\n",
    "        elif img_data.shape[0] > self.settings.num_slice:           # Removal of Emptier Peripheral Slices\n",
    "            img_data = img_data[int(np.ceil(-extra_slice / 2)) :\\\n",
    "                int(len(img_data) - np.floor(-extra_slice / 2))]\n",
    "        #else: assert(num_slice == self.settings.num_slice)\n",
    "          \n",
    "        # Item Dictionary Returning\n",
    "        #return img_data.unsqueeze(0)\n",
    "        return {'img_data': img_data.unsqueeze(0),\n",
    "                'resolution': f'[{num_row}, {num_col}]',\n",
    "                'subj_info': subj_info, 'num_slice': num_slice,\n",
    "                'preg_status': preg_status, 'orientation': subj_ori,\n",
    "                'h_flip': subj_h_flip, 'v_flip': subj_v_flip,\n",
    "                'position': str(subj_info[0x0018, 0x5100].value),\n",
    "                'num_series': int(subj_info.SeriesNumber)}\n",
    "\n",
    "# Dataset Initialization Example\n",
    "public_dataset = NCDataset(settings,\n",
    "                    mode = 'train',\n",
    "                    dataset = 'public')\n",
    "public_data = public_dataset.__getitem__('Breast_MRI_001')\n",
    "private_dataset = NCDataset(settings,\n",
    "                    mode = 'train',\n",
    "                    dataset = 'private')\n",
    "private_data = private_dataset.__getitem__('ID14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset.file_meta -------------------------------\n",
       "(0002, 0000) File Meta Information Group Length  UL: 202\n",
       "(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n",
       "(0002, 0002) Media Storage SOP Class UID         UI: MR Image Storage\n",
       "(0002, 0003) Media Storage SOP Instance UID      UI: 1.3.6.1.4.1.14519.5.2.1.33389863978639598148004524466314778584\n",
       "(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n",
       "(0002, 0012) Implementation Class UID            UI: 1.3.6.1.4.1.22213.1.143\n",
       "(0002, 0013) Implementation Version Name         SH: '0.5'\n",
       "(0002, 0016) Source Application Entity Title     AE: 'POSDA'\n",
       "-------------------------------------------------\n",
       "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
       "(0008, 0008) Image Type                          CS: ['ORIGINAL', 'PRIMARY', 'M', 'ND']\n",
       "(0008, 0012) Instance Creation Date              DA: '19900101'\n",
       "(0008, 0013) Instance Creation Time              TM: '084703.562000'\n",
       "(0008, 0016) SOP Class UID                       UI: MR Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.6.1.4.1.14519.5.2.1.33389863978639598148004524466314778584\n",
       "(0008, 0020) Study Date                          DA: '19900101'\n",
       "(0008, 0021) Series Date                         DA: '19900101'\n",
       "(0008, 0022) Acquisition Date                    DA: '19900101'\n",
       "(0008, 0023) Content Date                        DA: '19900101'\n",
       "(0008, 0030) Study Time                          TM: '080801.515000'\n",
       "(0008, 0031) Series Time                         TM: '084633.359000'\n",
       "(0008, 0032) Acquisition Time                    TM: '084633.042500'\n",
       "(0008, 0033) Content Time                        TM: '084703.562000'\n",
       "(0008, 0050) Accession Number                    SH: ''\n",
       "(0008, 0060) Modality                            CS: 'MR'\n",
       "(0008, 0070) Manufacturer                        LO: 'SIEMENS'\n",
       "(0008, 0090) Referring Physician's Name          PN: ''\n",
       "(0008, 1030) Study Description                   LO: 'MRI BREAST BILATERAL W/WO'\n",
       "(0008, 1032)  Procedure Code Sequence  1 item(s) ---- \n",
       "   (0008, 0100) Code Value                          SH: '0085X'\n",
       "   (0008, 0102) Coding Scheme Designator            SH: 'GEIIS'\n",
       "   (0008, 0103) Coding Scheme Version               SH: '0'\n",
       "   (0008, 0104) Code Meaning                        LO: 'MRI BREAST BILATERAL W WO'\n",
       "   ---------\n",
       "(0008, 103e) Series Description                  LO: 'ax t1 tse +c'\n",
       "(0008, 1090) Manufacturer's Model Name           LO: 'Avanto'\n",
       "(0010, 0010) Patient's Name                      PN: 'Breast_MRI_001'\n",
       "(0010, 0020) Patient ID                          LO: 'Breast_MRI_001'\n",
       "(0010, 0030) Patient's Birth Date                DA: ''\n",
       "(0010, 0040) Patient's Sex                       CS: 'F'\n",
       "(0010, 1010) Patient's Age                       AS: '041Y'\n",
       "(0010, 1020) Patient's Size                      DS: '1.6002032025'\n",
       "(0010, 1030) Patient's Weight                    DS: '90.2648931123'\n",
       "(0010, 21c0) Pregnancy Status                    US: 4\n",
       "(0010, 4000) Patient Comments                    LT: ''\n",
       "(0012, 0062) Patient Identity Removed            CS: 'YES'\n",
       "(0012, 0063) De-identification Method            LO: 'DICOMANON (rev R2010a) - PS 3.15-2008 Table E.1-1 - nondefault'\n",
       "(0013, 0010) Private Creator                     VR.LO: 'CTP'\n",
       "(0013, 1010) Private tag data                    VR.UN: Array of 22 elements\n",
       "(0013, 1013) Private tag data                    VR.UN: b'88622928'\n",
       "(0018, 0010) Contrast/Bolus Agent                LO: 'Magnevist'\n",
       "(0018, 0015) Body Part Examined                  CS: 'BREAST'\n",
       "(0018, 0020) Scanning Sequence                   CS: 'SE'\n",
       "(0018, 0021) Sequence Variant                    CS: ['SK', 'SP', 'OSP']\n",
       "(0018, 0022) Scan Options                        CS: ''\n",
       "(0018, 0023) MR Acquisition Type                 CS: '2D'\n",
       "(0018, 0025) Angio Flag                          CS: 'N'\n",
       "(0018, 0050) Slice Thickness                     DS: '3.0'\n",
       "(0018, 0080) Repetition Time                     DS: '600.0'\n",
       "(0018, 0081) Echo Time                           DS: '12.0'\n",
       "(0018, 0083) Number of Averages                  DS: '1.0'\n",
       "(0018, 0084) Imaging Frequency                   DS: '63.67636'\n",
       "(0018, 0085) Imaged Nucleus                      SH: '1H'\n",
       "(0018, 0086) Echo Number(s)                      IS: '1'\n",
       "(0018, 0087) Magnetic Field Strength             DS: '1.5'\n",
       "(0018, 0088) Spacing Between Slices              DS: '3.99'\n",
       "(0018, 0089) Number of Phase Encoding Steps      IS: '308'\n",
       "(0018, 0091) Echo Train Length                   IS: '7'\n",
       "(0018, 0093) Percent Sampling                    DS: '80.0'\n",
       "(0018, 0094) Percent Phase Field of View         DS: '100.0'\n",
       "(0018, 0095) Pixel Bandwidth                     DS: '130.0'\n",
       "(0018, 1000) Device Serial Number                LO: ''\n",
       "(0018, 1020) Software Versions                   LO: 'syngo MR B13 4VB13A'\n",
       "(0018, 1030) Protocol Name                       LO: ''\n",
       "(0018, 1041) Contrast/Bolus Volume               DS: '18.0'\n",
       "(0018, 1044) Contrast/Bolus Total Dose           DS: '0.0'\n",
       "(0018, 1048) Contrast/Bolus Ingredient           CS: ''\n",
       "(0018, 1049) Contrast/Bolus Ingredient Concentra DS: '0.0'\n",
       "(0018, 1200) Date of Last Calibration            DA: '19900101'\n",
       "(0018, 1251) Transmit Coil Name                  SH: 'Body'\n",
       "(0018, 1310) Acquisition Matrix                  US: [0, 256, 205, 0]\n",
       "(0018, 1312) In-plane Phase Encoding Direction   CS: 'ROW'\n",
       "(0018, 1314) Flip Angle                          DS: '180.0'\n",
       "(0018, 1315) Variable Flip Angle Flag            CS: 'N'\n",
       "(0018, 1316) SAR                                 DS: '2.270571685244'\n",
       "(0018, 1318) dB/dt                               DS: '0.0'\n",
       "(0018, 5100) Patient Position                    CS: 'FFP'\n",
       "(0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.14519.5.2.1.186051521067863971269584893740842397538\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.6.1.4.1.14519.5.2.1.175414966301645518238419021688341658582\n",
       "(0020, 0010) Study ID                            SH: ''\n",
       "(0020, 0011) Series Number                       IS: '26'\n",
       "(0020, 0012) Acquisition Number                  IS: '1'\n",
       "(0020, 0013) Instance Number                     IS: '34'\n",
       "(0020, 0032) Image Position (Patient)            DS: [-176.77492895291, -166.12590786308, -50.259795646808]\n",
       "(0020, 0037) Image Orientation (Patient)         DS: [0.9993283937409, -2.051034E-10, 0.036643709737, 2.049657E-10, 1, 7.5158E-12]\n",
       "(0020, 0052) Frame of Reference UID              UI: 1.3.6.1.4.1.14519.5.2.1.45736569925431297170708374639092465328\n",
       "(0020, 1040) Position Reference Indicator        LO: ''\n",
       "(0020, 1041) Slice Location                      DS: '-43.748351668134'\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 256\n",
       "(0028, 0011) Columns                             US: 256\n",
       "(0028, 0030) Pixel Spacing                       DS: [1.328125, 1.328125]\n",
       "(0028, 0100) Bits Allocated                      US: 16\n",
       "(0028, 0101) Bits Stored                         US: 12\n",
       "(0028, 0102) High Bit                            US: 11\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(0028, 0106) Smallest Image Pixel Value          VR.US: 0\n",
       "(0028, 0107) Largest Image Pixel Value           VR.US: 1648\n",
       "(0028, 1050) Window Center                       DS: '687.0'\n",
       "(0028, 1051) Window Width                        DS: '1450.0'\n",
       "(0032, 1060) Requested Procedure Description     LO: 'MRI BREAST BILATERAL W + W/O'\n",
       "(0040, 0254) Performed Procedure Step Descriptio LO: 'MRI BREAST BILATERAL W + W/O'\n",
       "(0040, 2017) Filler Order Number / Imaging Servi LO: ''\n",
       "(0088, 0140) Storage Media File-set UID          UI: 1.3.6.1.4.1.14519.5.2.1.281949768489412648962353822266799178366\n",
       "(7fe0, 0010) Pixel Data                          VR.OW: Array of 131072 elements"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_data['subj_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset.file_meta -------------------------------\n",
       "(0002, 0000) File Meta Information Group Length  UL: 206\n",
       "(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n",
       "(0002, 0002) Media Storage SOP Class UID         UI: MR Image Storage\n",
       "(0002, 0003) Media Storage SOP Instance UID      UI: 1.3.46.670589.11.71641.5.0.3096.2017071008325597048\n",
       "(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n",
       "(0002, 0012) Implementation Class UID            UI: 1.2.250.1.59.3.0.3.5.3\n",
       "(0002, 0013) Implementation Version Name         SH: 'ETIAM_DCMTK_353'\n",
       "(0002, 0016) Source Application Entity Title     AE: 'CDP5000'\n",
       "-------------------------------------------------\n",
       "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
       "(0008, 0008) Image Type                          CS: ['ORIGINAL', 'PRIMARY', 'M_SE', 'M', 'SE']\n",
       "(0008, 0012) Instance Creation Date              DA: '20170710'\n",
       "(0008, 0013) Instance Creation Time              TM: '090759.007'\n",
       "(0008, 0014) Instance Creator UID                UI: 1.3.46.670589.11.89.5\n",
       "(0008, 0016) SOP Class UID                       UI: MR Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.46.670589.11.71641.5.0.3096.2017071008325597048\n",
       "(0008, 0020) Study Date                          DA: '20170710'\n",
       "(0008, 0021) Series Date                         DA: '20170710'\n",
       "(0008, 0022) Acquisition Date                    DA: '20170710'\n",
       "(0008, 0023) Content Date                        DA: '20170710'\n",
       "(0008, 002a) Acquisition DateTime                DT: ''\n",
       "(0008, 0030) Study Time                          TM: '081118'\n",
       "(0008, 0031) Series Time                         TM: '082852.37000'\n",
       "(0008, 0032) Acquisition Time                    TM: '082901.13'\n",
       "(0008, 0033) Content Time                        TM: '082901.13'\n",
       "(0008, 0050) Accession Number                    SH: '2017041852'\n",
       "(0008, 0056) Instance Availability               CS: ''\n",
       "(0008, 0060) Modality                            CS: 'MR'\n",
       "(0008, 0061) Modalities in Study                 CS: ''\n",
       "(0008, 0064) Conversion Type                     CS: ''\n",
       "(0008, 0070) Manufacturer                        LO: 'Philips Medical Systems'\n",
       "(0008, 0080) Institution Name                    LO: 'Fundacao D.Anna Sommer Champalimaud'\n",
       "(0008, 0081) Institution Address                 ST: 'Av. Brasilia'\n",
       "(0008, 0090) Referring Physician's Name          PN: ''\n",
       "(0008, 0100) Code Value                          SH: ''\n",
       "(0008, 0102) Coding Scheme Designator            SH: ''\n",
       "(0008, 0104) Code Meaning                        LO: ''\n",
       "(0008, 1010) Station Name                        SH: 'HOST-U82Q96I6BI'\n",
       "(0008, 1030) Study Description                   LO: 'RM MAMARIA'\n",
       "(0008, 1032)  Procedure Code Sequence  1 item(s) ---- \n",
       "   (0008, 0100) Code Value                          SH: 'UNDEFINED'\n",
       "   (0008, 0102) Coding Scheme Designator            SH: 'UNDEFINED'\n",
       "   (0008, 0103) Coding Scheme Version               SH: 'UNDEFINED'\n",
       "   (0008, 0104) Code Meaning                        LO: 'UNDEFINED'\n",
       "   (0008, 010b) Context Group Extension Flag        CS: 'N'\n",
       "   ---------\n",
       "(0008, 103e) Series Description                  LO: 'T1W_TSE'\n",
       "(0008, 1040) Institutional Department Name       LO: 'Radilogia'\n",
       "(0008, 1050) Performing Physician's Name         PN: ''\n",
       "(0008, 1060) Name of Physician(s) Reading Study  PN: ''\n",
       "(0008, 1070) Operators' Name                     PN: ''\n",
       "(0008, 1080) Admitting Diagnoses Description     LO: ''\n",
       "(0008, 1090) Manufacturer's Model Name           LO: 'Ingenia'\n",
       "(0008, 1111)  Referenced Performed Procedure Step Sequence  1 item(s) ---- \n",
       "   (0008, 0012) Instance Creation Date              DA: '20170710'\n",
       "   (0008, 0013) Instance Creation Time              TM: '081118.612'\n",
       "   (0008, 0014) Instance Creator UID                UI: 1.3.46.670589.11.89.5\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: Modality Performed Procedure Step SOP Class\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.8040.2017071008111861000\n",
       "   (0020, 0013) Instance Number                     IS: '0'\n",
       "   (2005, 0014) Private Creator                     LO: 'Philips MR Imaging DD 005'\n",
       "   (2005, 1404) Private tag data                    SS: 1\n",
       "   (2005, 1406) [Unknown]                           SS: 1\n",
       "   ---------\n",
       "(0008, 1140)  Referenced Image Sequence  3 item(s) ---- \n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.3096.2017071008265197017\n",
       "   ---------\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.3096.2017071008265192008\n",
       "   ---------\n",
       "   (0008, 1150) Referenced SOP Class UID            UI: MR Image Storage\n",
       "   (0008, 1155) Referenced SOP Instance UID         UI: 1.3.46.670589.11.71641.5.0.3096.2017071008265193014\n",
       "   ---------\n",
       "(0010, 0010) Patient's Name                      PN: 'ID14'\n",
       "(0010, 0020) Patient ID                          LO: 'ID14'\n",
       "(0010, 0021) Issuer of Patient ID                LO: ''\n",
       "(0010, 0030) Patient's Birth Date                DA: 'ID14'\n",
       "(0010, 0032) Patient's Birth Time                TM: 'ID14'\n",
       "(0010, 0040) Patient's Sex                       CS: 'F'\n",
       "(0010, 1000) Other Patient IDs                   LO: '100286194'\n",
       "(0010, 1001) Other Patient Names                 PN: ''\n",
       "(0010, 1010) Patient's Age                       AS: 'ID14'\n",
       "(0010, 1030) Patient's Weight                    DS: '68.0'\n",
       "(0010, 2000) Medical Alerts                      LO: ''\n",
       "(0010, 2110) Allergies                           LO: ''\n",
       "(0010, 2160) Ethnic Group                        SH: ''\n",
       "(0010, 2180) Occupation                          SH: ''\n",
       "(0010, 21b0) Additional Patient History          LT: 'UNKNOWN'\n",
       "(0010, 21c0) Pregnancy Status                    US: 1\n",
       "(0010, 4000) Patient Comments                    LT: ''\n",
       "(0018, 0015) Body Part Examined                  CS: 'BREAST'\n",
       "(0018, 0020) Scanning Sequence                   CS: 'SE'\n",
       "(0018, 0021) Sequence Variant                    CS: 'SK'\n",
       "(0018, 0022) Scan Options                        CS: 'OTHER'\n",
       "(0018, 0023) MR Acquisition Type                 CS: '2D'\n",
       "(0018, 0050) Slice Thickness                     DS: '3.0'\n",
       "(0018, 0080) Repetition Time                     DS: '702.870971679687'\n",
       "(0018, 0081) Echo Time                           DS: '10.0'\n",
       "(0018, 0083) Number of Averages                  DS: '2.0'\n",
       "(0018, 0084) Imaging Frequency                   DS: '127.762712'\n",
       "(0018, 0085) Imaged Nucleus                      SH: '1H'\n",
       "(0018, 0086) Echo Number(s)                      IS: '1'\n",
       "(0018, 0087) Magnetic Field Strength             DS: '3.0'\n",
       "(0018, 0088) Spacing Between Slices              DS: '3.0'\n",
       "(0018, 0089) Number of Phase Encoding Steps      IS: '416'\n",
       "(0018, 0091) Echo Train Length                   IS: '5'\n",
       "(0018, 0093) Percent Sampling                    DS: '100.383140563964'\n",
       "(0018, 0094) Percent Phase Field of View         DS: '130.43478158804'\n",
       "(0018, 0095) Pixel Bandwidth                     DS: '436.0'\n",
       "(0018, 1000) Device Serial Number                LO: '71641'\n",
       "(0018, 1010) Secondary Capture Device ID         LO: ''\n",
       "(0018, 1016) Secondary Capture Device Manufactur LO: ''\n",
       "(0018, 1018) Secondary Capture Device Manufactur LO: ''\n",
       "(0018, 1019) Secondary Capture Device Software V LO: ''\n",
       "(0018, 1020) Software Versions                   LO: ['5.3.0', '5.3.0.3']\n",
       "(0018, 1022) Video Image Format Acquired         SH: ''\n",
       "(0018, 1023) Digital Image Format Acquired       LO: ''\n",
       "(0018, 1030) Protocol Name                       LO: 'T1W_TSE'\n",
       "(0018, 1081) Low R-R Value                       IS: '0'\n",
       "(0018, 1082) High R-R Value                      IS: '0'\n",
       "(0018, 1083) Intervals Acquired                  IS: '0'\n",
       "(0018, 1084) Intervals Rejected                  IS: '0'\n",
       "(0018, 1088) Heart Rate                          IS: '0'\n",
       "(0018, 1100) Reconstruction Diameter             DS: '339.0'\n",
       "(0018, 1250) Receive Coil Name                   SH: 'SENSE_BREAST_7M_'\n",
       "(0018, 1310) Acquisition Matrix                  US: [0, 423, 416, 0]\n",
       "(0018, 1312) In-plane Phase Encoding Direction   CS: 'ROW'\n",
       "(0018, 1314) Flip Angle                          DS: '90.0'\n",
       "(0018, 1316) SAR                                 DS: '2.10955715179443'\n",
       "(0018, 1318) dB/dt                               DS: '82.7510452270507'\n",
       "(0018, 1320) B1rms                               FL: 1.9798811674118042\n",
       "(0018, 5100) Patient Position                    CS: 'FFP'\n",
       "(0018, 9073) Acquisition Duration                FD: 231.94741821289062\n",
       "(0018, 9087) Diffusion b-value                   FD: 0.0\n",
       "(0018, 9089) Diffusion Gradient Orientation      FD: [0.0, 0.0, 0.0]\n",
       "(0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.23849.23212228212522292623\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.46.670589.11.71641.5.0.3096.2017071008285239035\n",
       "(0020, 0010) Study ID                            SH: '537001878'\n",
       "(0020, 0011) Series Number                       IS: '201'\n",
       "(0020, 0012) Acquisition Number                  IS: '2'\n",
       "(0020, 0013) Instance Number                     IS: '41'\n",
       "(0020, 0032) Image Position (Patient)            DS: [-165.88848899741, -146.37823748588, 28.8661248559565]\n",
       "(0020, 0037) Image Orientation (Patient)         DS: [0.99941027164459, 0, 0.03433802351355, 0, 1, 0]\n",
       "(0020, 0052) Frame of Reference UID              UI: 1.3.46.670589.11.71641.5.0.10712.2017071008242258000\n",
       "(0020, 0060) Laterality                          CS: ''\n",
       "(0020, 0100) Temporal Position Identifier        IS: '1'\n",
       "(0020, 0105) Number of Temporal Positions        IS: '1'\n",
       "(0020, 1040) Position Reference Indicator        LO: ''\n",
       "(0020, 1041) Slice Location                      DS: '-34.545384676145'\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 720\n",
       "(0028, 0011) Columns                             US: 720\n",
       "(0028, 0030) Pixel Spacing                       DS: [0.47101449966430, 0.47101449966430]\n",
       "(0028, 0100) Bits Allocated                      US: 16\n",
       "(0028, 0101) Bits Stored                         US: 12\n",
       "(0028, 0102) High Bit                            US: 11\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(0028, 1050) Window Center                       DS: '1070.0'\n",
       "(0028, 1051) Window Width                        DS: '1860.0'\n",
       "(0028, 1052) Rescale Intercept                   DS: '0.0'\n",
       "(0028, 1053) Rescale Slope                       DS: '5.1081807081807'\n",
       "(0028, 1054) Rescale Type                        LO: 'normalized'\n",
       "(0032, 1032) Requesting Physician                PN: ''\n",
       "(0032, 1033) Requesting Service                  LO: ''\n",
       "(0032, 1060) Requested Procedure Description     LO: 'RM MAMARIA'\n",
       "(0032, 1064)  Requested Procedure Code Sequence  1 item(s) ---- \n",
       "   (0008, 0104) Code Meaning                        LO: ''\n",
       "   ---------\n",
       "(0032, 1070) Requested Contrast Agent            LO: ''\n",
       "(0032, 4000) Study Comments                      LT: ''\n",
       "(0038, 0010) Admission ID                        LO: ''\n",
       "(0038, 0050) Special Needs                       LO: ''\n",
       "(0038, 0300) Current Patient Location            LO: ''\n",
       "(0038, 0500) Patient State                       LO: ''\n",
       "(0040, 0006) Scheduled Performing Physician's Na PN: ''\n",
       "(0040, 0007) Scheduled Procedure Step Descriptio LO: ''\n",
       "(0040, 0008)  Scheduled Protocol Code Sequence  1 item(s) ---- \n",
       "   (0008, 0104) Code Meaning                        LO: ''\n",
       "   ---------\n",
       "(0040, 0241) Performed Station AE Title          AE: 'RM1FC'\n",
       "(0040, 0242) Performed Station Name              SH: ''\n",
       "(0040, 0243) Performed Location                  SH: ''\n",
       "(0040, 0244) Performed Procedure Step Start Date DA: '20170710'\n",
       "(0040, 0245) Performed Procedure Step Start Time TM: '081118'\n",
       "(0040, 0250) Performed Procedure Step End Date   DA: '20170710'\n",
       "(0040, 0251) Performed Procedure Step End Time   TM: '081118'\n",
       "(0040, 0252) Performed Procedure Step Status     CS: ''\n",
       "(0040, 0253) Performed Procedure Step ID         SH: '537001878'\n",
       "(0040, 0254) Performed Procedure Step Descriptio LO: 'RM MAMARIA'\n",
       "(0040, 0255) Performed Procedure Type Descriptio LO: ''\n",
       "(0040, 0260)  Performed Protocol Code Sequence  1 item(s) ---- \n",
       "   (0008, 0100) Code Value                          SH: 'UNDEFINED'\n",
       "   (0008, 0102) Coding Scheme Designator            SH: 'UNDEFINED'\n",
       "   (0008, 0103) Coding Scheme Version               SH: 'UNDEFINED'\n",
       "   (0008, 0104) Code Meaning                        LO: 'UNDEFINED'\n",
       "   (0008, 010b) Context Group Extension Flag        CS: 'N'\n",
       "   ---------\n",
       "(0040, 0275)  Request Attributes Sequence  1 item(s) ---- \n",
       "   (0008, 0050) Accession Number                    SH: '2017041852'\n",
       "   (0032, 1060) Requested Procedure Description     LO: 'RM MAMARIA'\n",
       "   (0040, 0007) Scheduled Procedure Step Descriptio LO: 'RM MAMARIA'\n",
       "   (0040, 0008)  Scheduled Protocol Code Sequence  1 item(s) ---- \n",
       "      (0008, 0100) Code Value                          SH: 'UNDEFINED'\n",
       "      (0008, 0102) Coding Scheme Designator            SH: 'UNDEFINED'\n",
       "      (0008, 0103) Coding Scheme Version               SH: 'UNDEFINED'\n",
       "      (0008, 0104) Code Meaning                        LO: 'UNDEFINED'\n",
       "      ---------\n",
       "   (0040, 0009) Scheduled Procedure Step ID         SH: '2017041852'\n",
       "   (0040, 0012) Pre-Medication                      LO: ''\n",
       "   (0040, 0400) Comments on the Scheduled Procedure LT: ''\n",
       "   (0040, 1001) Requested Procedure ID              SH: '2017041852'\n",
       "   ---------\n",
       "(0040, 0280) Comments on the Performed Procedure ST: ''\n",
       "(0040, 0400) Comments on the Scheduled Procedure LT: ''\n",
       "(0040, 1001) Requested Procedure ID              SH: '2017041852'\n",
       "(0040, 1002) Reason for the Requested Procedure  LO: ''\n",
       "(0040, 1003) Requested Procedure Priority        SH: ''\n",
       "(0040, 1004) Patient Transport Arrangements      LO: ''\n",
       "(0040, 1005) Requested Procedure Location        LO: ''\n",
       "(0040, 1400) Requested Procedure Comments        LT: ''\n",
       "(0040, 2001) Reason for the Imaging Service Requ LO: ''\n",
       "(0040, 2004) Issue Date of Imaging Service Reque DA: '20170710'\n",
       "(0040, 2005) Issue Time of Imaging Service Reque TM: '081118.565'\n",
       "(0040, 2009) Order Enterer's Location            SH: ''\n",
       "(0040, 2010) Order Callback Phone Number         SH: ''\n",
       "(0040, 2400) Imaging Service Request Comments    LT: ''\n",
       "(2001, 0010) Private Creator                     LO: 'Philips Imaging DD 001'\n",
       "(2001, 0011) Private Creator                     LO: 'Philips Imaging DD 002'\n",
       "(2001, 1001) [Chemical Shift]                    FL: 0.0\n",
       "(2001, 1002) [Chemical Shift Number MR]          IS: '0'\n",
       "(2001, 1003) [Diffusion B-Factor]                FL: 0.0\n",
       "(2001, 1004) [Diffusion Direction]               CS: ''\n",
       "(2001, 1006) [Image Enhanced]                    CS: 'N'\n",
       "(2001, 1007) [Image Type ED ES]                  CS: 'U'\n",
       "(2001, 1008) [Phase Number]                      IS: '1'\n",
       "(2001, 1009) [Unknown]                           FL: 0.0\n",
       "(2001, 100a) [Slice Number MR]                   IS: '41'\n",
       "(2001, 100b) [Slice Orientation]                 CS: 'TRANSVERSAL'\n",
       "(2001, 100c) [Unknown]                           CS: 'N'\n",
       "(2001, 100e) [Unknown]                           CS: 'N'\n",
       "(2001, 100f) [Unknown]                           SS: 0\n",
       "(2001, 1010) [Cardiac Sync]                      CS: 'NO'\n",
       "(2001, 1011) [Diffusion Echo Time]               FL: 0.0\n",
       "(2001, 1012) [Dynamic Series]                    CS: 'N'\n",
       "(2001, 1013) [EPI Factor]                        SL: 1\n",
       "(2001, 1014) [Number of Echoes]                  SL: 1\n",
       "(2001, 1015) [Number of Locations]               SS: 1\n",
       "(2001, 1016) [Number of PC Directions]           SS: 0\n",
       "(2001, 1017) [Number of Phases MR]               SL: 1\n",
       "(2001, 1018) [Number of Slices MR]               SL: 60\n",
       "(2001, 1019) [Partial Matrix Scanned]            CS: 'N'\n",
       "(2001, 101a) [PC Velocity]                       FL: [0.0, 0.0, 0.0]\n",
       "(2001, 101b) [Prepulse Delay]                    FL: 0.0\n",
       "(2001, 101c) [Prepulse Type]                     CS: 'NO'\n",
       "(2001, 101d) [Reconstruction Number MR]          IS: '1'\n",
       "(2001, 101e) [Unknown]                           CS: ''\n",
       "(2001, 101f) [Respiration Sync]                  CS: 'NO'\n",
       "(2001, 1020) [Scanning Technique Description MR] LO: 'TSE'\n",
       "(2001, 1021) [SPIR]                              CS: 'N'\n",
       "(2001, 1022) [Water Fat Shift]                   FL: 0.9964969754219055\n",
       "(2001, 1023) [Flip Angle Philips]                DS: '90.0'\n",
       "(2001, 1024) [Interactive]                       CS: 'N'\n",
       "(2001, 1025) [Echo Time Display MR]              SH: '10'\n",
       "(2001, 105f)  [Stack Sequence]  1 item(s) ---- \n",
       "   (2001, 0010) Private Creator                     LO: 'Philips Imaging DD 001'\n",
       "   (2001, 102d) [Number of Stack Slices]            SS: 60\n",
       "   (2001, 1032) [Stack Radial Angle]                FL: 0.0\n",
       "   (2001, 1033) [Stack Radial Axis]                 CS: 'AP'\n",
       "   (2001, 1035) [Stack Slice Number]                SS: 1\n",
       "   (2001, 1036) [Stack Type]                        CS: 'PARALLEL'\n",
       "   (2005, 0010) Private Creator                     LO: 'Philips MR Imaging DD 001'\n",
       "   (2005, 0014) Private Creator                     LO: 'Philips MR Imaging DD 005'\n",
       "   (2005, 0015) Private Creator                     LO: 'Philips MR Imaging DD 006'\n",
       "   (2005, 1071) [Unknown]                           FL: -1.9678106307983398\n",
       "   (2005, 1072) [Unknown]                           FL: 0.0\n",
       "   (2005, 1073) [Unknown]                           FL: 0.0\n",
       "   (2005, 1074) [Unknown]                           FL: 260.0\n",
       "   (2005, 1075) [Unknown]                           FL: 180.0\n",
       "   (2005, 1076) [Unknown]                           FL: 339.13043212890625\n",
       "   (2005, 1078) [Unknown]                           FL: 22.951475143432617\n",
       "   (2005, 1079) [Unknown]                           FL: 3.1991500854492188\n",
       "   (2005, 107a) [Unknown]                           FL: 4.423012733459473\n",
       "   (2005, 107b) [Unknown]                           CS: 'RL'\n",
       "   (2005, 107e) [Unknown]                           FL: 3.0\n",
       "   (2005, 1081) [Unknown]                           CS: 'FH'\n",
       "   (2005, 143c) [Unknown]                           FL: -0.5\n",
       "   (2005, 143d) [Unknown]                           FL: 0.0\n",
       "   (2005, 143e) [Unknown]                           FL: 0.0\n",
       "   (2005, 1567) Private tag data                    IS: '0'\n",
       "   ---------\n",
       "(2001, 1060) [Number of Stacks]                  SL: 1\n",
       "(2001, 1061) [Unknown]                           CS: 'N'\n",
       "(2001, 1062) [Unknown]                           CS: 'N'\n",
       "(2001, 1063) [Examination Source]                CS: 'ELSEWHERE'\n",
       "(2001, 1077) [GL TrafoType]                      CS: ''\n",
       "(2001, 107b) [Acquisition Number]                IS: '2'\n",
       "(2001, 1081) [Number of Dynamic Scans]           IS: '1'\n",
       "(2001, 1082) [Echo Train Length]                 IS: '5'\n",
       "(2001, 1083) [Imaging Frequency]                 DS: '127.762712'\n",
       "(2001, 1084) [Inversion Time]                    DS: '0.0'\n",
       "(2001, 1085) [Magnetic Field Strength]           DS: '3.0'\n",
       "(2001, 1086) [Unknown]                           IS: '0'\n",
       "(2001, 1087) [Imaged Nucleus]                    SH: '1H'\n",
       "(2001, 1088) [Number of Averages]                DS: '2.0'\n",
       "(2001, 1089) [Phase FOV Percent]                 DS: '0.0'\n",
       "(2001, 108a) [Sampling Percent]                  DS: '0.0'\n",
       "(2001, 108b) [Unknown]                           SH: 'S'\n",
       "(2001, 10c8) Private tag data                    LO: 'Mama'\n",
       "(2001, 10cc) [Unknown]                           ST: ''\n",
       "(2001, 10f1) [Prospective Motion Correction]     FL: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "(2001, 10f2) [Retrospective Motion Correction]   FL: [1.6999999760721821e+38, 1.6999999760721821e+38, 1.6999999760721821e+38, 1.6999999760721821e+38, 1.6999999760721821e+38, 1.6999999760721821e+38]\n",
       "(2001, 116b) Private tag data                    LO: ''\n",
       "(2005, 0010) Private Creator                     LO: 'Philips MR Imaging DD 001'\n",
       "(2005, 0011) Private Creator                     LO: 'Philips MR Imaging DD 002'\n",
       "(2005, 0012) Private Creator                     LO: 'Philips MR Imaging DD 003'\n",
       "(2005, 0013) Private Creator                     LO: 'Philips MR Imaging DD 004'\n",
       "(2005, 0014) Private Creator                     LO: 'Philips MR Imaging DD 005'\n",
       "(2005, 0015) Private Creator                     LO: 'Philips MR Imaging DD 006'\n",
       "(2005, 1000) [Unknown]                           FL: -1.9678106307983398\n",
       "(2005, 1001) [Unknown]                           FL: -0.0\n",
       "(2005, 1002) [Unknown]                           FL: -0.0\n",
       "(2005, 1008) [Unknown]                           FL: 22.951475143432617\n",
       "(2005, 1009) [Unknown]                           FL: 34.680572509765625\n",
       "(2005, 100a) [Unknown]                           FL: 3.341365098953247\n",
       "(2005, 100b) [Unknown]                           FL: 1834.932373046875\n",
       "(2005, 100c) [Unknown]                           FL: 0.0035355985164642334\n",
       "(2005, 100d) [Unknown]                           FL: 0.0\n",
       "(2005, 100e) [Unknown]                           FL: 0.25027987360954285\n",
       "(2005, 100f) [Window Center]                     DS: '1070.0'\n",
       "(2005, 1010) [Window Width]                      DS: '1860.0'\n",
       "(2005, 1011) [Unknown]                           CS: 'M'\n",
       "(2005, 1012) [Unknown]                           CS: 'N'\n",
       "(2005, 1013) [Unknown]                           CS: 'NO'\n",
       "(2005, 1014) [Unknown]                           CS: 'N'\n",
       "(2005, 1015) [Unknown]                           CS: 'N'\n",
       "(2005, 1016) [Unknown]                           CS: 'N'\n",
       "(2005, 1017) [Unknown]                           CS: 'N'\n",
       "(2005, 1018) [Unknown]                           LO: ''\n",
       "(2005, 1019) [Unknown]                           CS: 'N'\n",
       "(2005, 101a) [Unknown]                           SS: 0\n",
       "(2005, 101b) [Unknown]                           CS: 'N'\n",
       "(2005, 101c) [Unknown]                           CS: 'N'\n",
       "(2005, 101d) [Unknown]                           SS: 423\n",
       "(2005, 101e) [Unknown]                           SH: 'compose'\n",
       "(2005, 101f) [Unknown]                           SH: 'compose'\n",
       "(2005, 1020) [Number of Chemical Shift]          SL: 0\n",
       "(2005, 1021) [Unknown]                           SS: 1\n",
       "(2005, 1022) [Unknown]                           IS: '0'\n",
       "(2005, 1023) [Unknown]                           SS: 0\n",
       "(2005, 1025) [Unknown]                           SS: 0\n",
       "(2005, 1026) [Unknown]                           CS: 'N'\n",
       "(2005, 1027) [Unknown]                           CS: 'MINIMUM'\n",
       "(2005, 1028) [Unknown]                           CS: 'N'\n",
       "(2005, 1029) [Unknown]                           CS: 'N'\n",
       "(2005, 102a) [Unknown]                           IS: '566036672'\n",
       "(2005, 102b) [Unknown]                           SS: 100\n",
       "(2005, 102c) [Unknown]                           CS: 'N'\n",
       "(2005, 102d) [Unknown]                           IS: '0'\n",
       "(2005, 102e) [Unknown]                           CS: 'N'\n",
       "(2005, 102f) [Unknown]                           CS: 'N'\n",
       "(2005, 1030) [Repetition Time]                   FL: [702.8709716796875, 0.0]\n",
       "(2005, 1031) [Unknown]                           CS: 'N'\n",
       "(2005, 1032) [Unknown]                           CS: ''\n",
       "(2005, 1033) [Acquisition Duration]              FL: 231.94741821289062\n",
       "(2005, 1034) [Unknown]                           CS: 'Y'\n",
       "(2005, 1035) [Unknown]                           CS: 'PIXEL'\n",
       "(2005, 1036) [Unknown]                           CS: 'N'\n",
       "(2005, 1037) [Unknown]                           CS: 'N'\n",
       "(2005, 1038) [Unknown]                           CS: 'N'\n",
       "(2005, 1039) [Unknown]                           CS: 'N'\n",
       "(2005, 103a) [Unknown]                           SH: ''\n",
       "(2005, 103b) [Unknown]                           CS: 'N'\n",
       "(2005, 103c) [Unknown]                           CS: 'N'\n",
       "(2005, 103d) [Unknown]                           SS: 1\n",
       "(2005, 103e) [Unknown]                           SL: 0\n",
       "(2005, 105f) [Unknown]                           CS: 'UNKNOWN'\n",
       "(2005, 1060) [Unknown]                           IS: '-1'\n",
       "(2005, 1061) [Unknown]                           CS: 'NO'\n",
       "(2005, 1063) [Unknown]                           SS: 0\n",
       "(2005, 106e) [Unknown]                           CS: 'SE'\n",
       "(2005, 106f) [Unknown]                           CS: 'MS'\n",
       "(2005, 1070) [Unknown]                           LO: ''\n",
       "(2005, 1081) [Unknown]                           CS: ''\n",
       "(2005, 1086) [Unknown]                           SS: 0\n",
       "(2005, 109f) [Unknown]                           CS: ''\n",
       "(2005, 10a0) [Unknown]                           FL: 0.0\n",
       "(2005, 10a1) [Syncra Scan Type]                  CS: 'SENSE'\n",
       "(2005, 10a2) [Unknown]                           CS: 'N'\n",
       "(2005, 10a8) [Unknown]                           DS: '0.0'\n",
       "(2005, 10a9) [Unknown]                           CS: '2D'\n",
       "(2005, 10b0) [Diffusion Direction RL]            FL: 0.0\n",
       "(2005, 10b1) [Diffusion Direction AP]            FL: 0.0\n",
       "(2005, 10b2) [Diffusion Direction FH]            FL: 0.0\n",
       "(2005, 10c0) [Unknown]                           CS: 'SE'\n",
       "(2005, 1134) Private tag data                    LT: ''\n",
       "(2005, 1199) [Unknown]                           UL: 1\n",
       "(2005, 1200) [Unknown]                           UL: 1\n",
       "(2005, 1201) [Unknown]                           UL: 0\n",
       "(2005, 1213) [Unknown]                           UL: 1\n",
       "(2005, 1245) [Unknown]                           SS: 2\n",
       "(2005, 1249) [Unknown]                           SS: 0\n",
       "(2005, 1251) [Unknown]                           SS: 0\n",
       "(2005, 1252) [Unknown]                           SS: 0\n",
       "(2005, 1253) [Unknown]                           SS: 0\n",
       "(2005, 1256) [Unknown]                           SS: 0\n",
       "(2005, 1325) [Unknown]                           CS: 'N'\n",
       "(2005, 1326) [Unknown]                           FL: 0.0\n",
       "(2005, 1327) [Unknown]                           CS: 'REAL'\n",
       "(2005, 1328) [Unknown]                           CS: 'ORIGINAL'\n",
       "(2005, 1329) [Unknown]                           FL: 50.0\n",
       "(2005, 1331) [Unknown]                           SS: 0\n",
       "(2005, 1334) [Unknown]                           CS: 'UNKNOWN'\n",
       "(2005, 1335) [Unknown]                           CS: 'UNKNOWN'\n",
       "(2005, 1336) [Unknown]                           FL: 0.0\n",
       "(2005, 1337) [Unknown]                           FL: 0.0\n",
       "(2005, 1338) [Unknown]                           FL: 0.0\n",
       "(2005, 1340) [Unknown]                           CS: 'PRE_FT'\n",
       "(2005, 1341) [Unknown]                           CS: 'UNKNOWN'\n",
       "(2005, 1342) [Unknown]                           CS: 'FID'\n",
       "(2005, 1343) [Unknown]                           CS: 'Y'\n",
       "(2005, 1345) [Unknown]                           CS: 'NO'\n",
       "(2005, 1346) [Unknown]                           CS: 'HERTZ'\n",
       "(2005, 1347) [Unknown]                           FL: 0.0\n",
       "(2005, 1348) [Unknown]                           CS: 'OFF'\n",
       "(2005, 1349) [Unknown]                           FL: 0.0\n",
       "(2005, 1351) [Unknown]                           SS: 0\n",
       "(2005, 1352) [Unknown]                           SS: 0\n",
       "(2005, 1354) [Unknown]                           CS: ''\n",
       "(2005, 1355) [Unknown]                           FL: Array of 30 elements\n",
       "(2005, 1356) [Unknown]                           CS: 'NO'\n",
       "(2005, 1357) [Unknown]                           SS: 0\n",
       "(2005, 1358) [Unknown]                           LO: ''\n",
       "(2005, 1359) [Unknown]                           FL: 1.0\n",
       "(2005, 1360) [Unknown]                           FL: 0.0\n",
       "(2005, 1362) [Unknown]                           FL: 0.0\n",
       "(2005, 1363) [Unknown]                           FL: 0.0\n",
       "(2005, 1364) [Unknown]                           CS: 'NO'\n",
       "(2005, 1370) [Unknown]                           SS: 0\n",
       "(2005, 1381) [Unknown]                           IS: '3'\n",
       "(2005, 1382) [Unknown]                           UL: 1\n",
       "(2005, 1391) [Unknown]                           PN: ''\n",
       "(2005, 1392) [Unknown]                           IS: '0'\n",
       "(2005, 1393) [Unknown]                           IS: '-1'\n",
       "(2005, 1395) [Unknown]                           ST: '7,IMAGE_TYPE,SLICE_NUMBER,ECHO_NUMBER,PHASE_NUMBER,DYNAMIC_SCAN,CHEMICAL_SHIFT,DIFF_B_VALUE_NO,ASCENDING,NONE,0,0'\n",
       "(2005, 1396) [Unknown]                           CS: 'NO'\n",
       "(2005, 1397) [Unknown]                           LO: 'SRT.T-04000.Breast'\n",
       "(2005, 1398) [Unknown]                           CS: 'NO'\n",
       "(2005, 1399) [Unknown]                           CS: 'NO'\n",
       "(2005, 1400) [Unknown]                           CS: 'YES'\n",
       "(2005, 1401) [Unknown]                           UL: 1\n",
       "(2005, 1402)  [Unknown]  1 item(s) ---- \n",
       "   (0008, 0100) Code Value                          SH: 'UNDEFINED'\n",
       "   (0008, 0102) Coding Scheme Designator            SH: 'UNDEFINED'\n",
       "   (0008, 0103) Coding Scheme Version               SH: 'UNDEFINED'\n",
       "   (0008, 0104) Code Meaning                        LO: 'UNDEFINED'\n",
       "   ---------\n",
       "(2005, 1403) [Unknown]                           UL: 0\n",
       "(2005, 1409) [Unknown]                           DS: '0.0'\n",
       "(2005, 140a) [Unknown]                           DS: '5.1081807081807'\n",
       "(2005, 140b) [Unknown]                           LO: 'normalized'\n",
       "(2005, 140f)  [Unknown]  1 item(s) ---- \n",
       "   (0008, 002a) Acquisition DateTime                DT: '20170710'\n",
       "   (0008, 9123) Creator-Version UID                 UI: 1.3.46.670589.11\n",
       "   (0008, 9205) Pixel Presentation                  CS: 'MONOCHROME'\n",
       "   (0008, 9206) Volumetric Properties               CS: 'VOLUME'\n",
       "   (0008, 9207) Volume Based Calculation Technique  CS: 'NONE'\n",
       "   (0008, 9209) Acquisition Contrast                CS: 'T1'\n",
       "   (0018, 9005) Pulse Sequence Name                 SH: 'TSE'\n",
       "   (0018, 9008) Echo Pulse Sequence                 CS: 'SPIN'\n",
       "   (0018, 9009) Inversion Recovery                  CS: 'NO'\n",
       "   (0018, 9011) Multiple Spin Echo                  CS: 'YES'\n",
       "   (0018, 9012) Multi-planar Excitation             CS: 'NO'\n",
       "   (0018, 9014) Phase Contrast                      CS: 'NO'\n",
       "   (0018, 9015) Time of Flight Contrast             CS: 'NO'\n",
       "   (0018, 9016) Spoiling                            CS: 'NONE'\n",
       "   (0018, 9017) Steady State Pulse Sequence         CS: 'NONE'\n",
       "   (0018, 9018) Echo Planar Pulse Sequence          CS: 'NO'\n",
       "   (0018, 9019) Tag Angle First Axis                FD: 7.23e+75\n",
       "   (0018, 9020) Magnetization Transfer              CS: 'NONE'\n",
       "   (0018, 9021) T2 Preparation                      CS: 'NO'\n",
       "   (0018, 9022) Blood Signal Nulling                CS: 'NO'\n",
       "   (0018, 9024) Saturation Recovery                 CS: 'NO'\n",
       "   (0018, 9025) Spectrally Selected Suppression     CS: 'NONE'\n",
       "   (0018, 9026) Spectrally Selected Excitation      CS: 'NONE'\n",
       "   (0018, 9027) Spatial Pre-saturation              CS: 'NONE'\n",
       "   (0018, 9028) Tagging                             CS: 'NONE'\n",
       "   (0018, 9029) Oversampling Phase                  CS: '2D'\n",
       "   (0018, 9030) Tag Spacing First Dimension         FD: 7.23e+75\n",
       "   (0018, 9032) Geometry of k-Space Traversal       CS: 'RECTILINEAR'\n",
       "   (0018, 9033) Segmented k-Space Traversal         CS: 'PARTIAL'\n",
       "   (0018, 9034) Rectilinear Phase Encode Reordering CS: 'UNKNOWN'\n",
       "   (0018, 9035) Tag Thickness                       FD: 0.0\n",
       "   (0018, 9036) Partial Fourier Direction           CS: ''\n",
       "   (0018, 9037) Cardiac Synchronization Technique   CS: 'NONE'\n",
       "   (0018, 9043) Receive Coil Type                   CS: 'MULTICOIL'\n",
       "   (0018, 9044) Quadrature Receive Coil             CS: 'NO'\n",
       "   (0018, 9047) Multi-Coil Element Name             SH: ''\n",
       "   (0018, 9050) Transmit Coil Manufacturer Name     LO: ''\n",
       "   (0018, 9051) Transmit Coil Type                  CS: 'SURFACE'\n",
       "   (0018, 9053) Chemical Shift Reference            FD: [4.68, 4.68]\n",
       "   (0018, 9058) MR Acquisition Frequency Encoding S US: 423\n",
       "   (0018, 9059) De-coupling                         CS: 'NO'\n",
       "   (0018, 9060) De-coupled Nucleus                  CS: ''\n",
       "   (0018, 9062) De-coupling Method                  CS: ''\n",
       "   (0018, 9064) k-space Filtering                   CS: 'RIESZ'\n",
       "   (0018, 9065) Time Domain Filtering               CS: ''\n",
       "   (0018, 9069) Parallel Reduction Factor In-plane  FD: 4.0\n",
       "   (0018, 9075) Diffusion Directionality            CS: 'NONE'\n",
       "   (0018, 9077) Parallel Acquisition                CS: 'YES'\n",
       "   (0018, 9078) Parallel Acquisition Technique      CS: 'SENSE'\n",
       "   (0018, 9079) Inversion Times                     FD: 0.0\n",
       "   (0018, 9080) Metabolite Map Description          ST: 'WATER'\n",
       "   (0018, 9081) Partial Fourier                     CS: 'NO'\n",
       "   (0018, 9085) Cardiac Signal Source               CS: ''\n",
       "   (0018, 9087) Diffusion b-value                   FD: 7.23e+75\n",
       "   (0018, 9089) Diffusion Gradient Orientation      FD: [7.23e+75, 7.23e+75, 7.23e+75]\n",
       "   (0018, 9090) Velocity Encoding Direction         FD: [0.0, 0.0, 0.0]\n",
       "   (0018, 9091) Velocity Encoding Minimum Value     FD: 0.0\n",
       "   (0018, 9093) Number of k-Space Trajectories      US: 26\n",
       "   (0018, 9094) Coverage of k-Space                 CS: ''\n",
       "   (0018, 9101) Frequency Correction                CS: 'NO'\n",
       "   (0018, 9147) Diffusion Anisotropy Type           CS: ''\n",
       "   (0018, 9155) Parallel Reduction Factor out-of-pl FD: 1.0\n",
       "   (0018, 9168) Parallel Reduction Factor Second In FD: 1.0\n",
       "   (0018, 9169) Cardiac Beat Rejection Technique    CS: ''\n",
       "   (0018, 9170) Respiratory Motion Compensation Tec CS: 'NONE'\n",
       "   (0018, 9171) Respiratory Signal Source           CS: 'NONE'\n",
       "   (0018, 9172) Bulk Motion Compensation Technique  CS: 'NONE'\n",
       "   (0018, 9174) Applicable Safety Standard Agency   CS: 'IEC'\n",
       "   (0018, 9176)  Operating Mode Sequence  3 item(s) ---- \n",
       "      (0018, 9177) Operating Mode Type                 CS: 'STATIC FIELD'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_FIRST_LEVEL'\n",
       "      ---------\n",
       "      (0018, 9177) Operating Mode Type                 CS: 'RF'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_FIRST_LEVEL'\n",
       "      ---------\n",
       "      (0018, 9177) Operating Mode Type                 CS: 'GRADIENT'\n",
       "      (0018, 9178) Operating Mode                      CS: 'IEC_NORMAL'\n",
       "      ---------\n",
       "   (0018, 9179) Specific Absorption Rate Definition CS: 'IEC_WHOLE_BODY'\n",
       "   (0018, 9180) Gradient Output Type                CS: 'DB_DT'\n",
       "   (0018, 9181) Specific Absorption Rate Value      FD: 2.1095571517944336\n",
       "   (0018, 9182) Gradient Output                     FD: 82.75104522705078\n",
       "   (0018, 9183) Flow Compensation Direction         CS: ''\n",
       "   (0018, 9199) Water Referenced Phase Correction   CS: 'NO'\n",
       "   (0018, 9200) MR Spectroscopy Acquisition Type    CS: ''\n",
       "   (0018, 9231) MR Acquisition Phase Encoding Steps US: 416\n",
       "   (0018, 9232) MR Acquisition Phase Encoding Steps US: 1\n",
       "   (0018, 9240) RF Echo Train Length                US: 5\n",
       "   (0018, 9241) Gradient Echo Train Length          US: 0\n",
       "   (0018, 9602) Diffusion b-value XX                FD: 7.23e+75\n",
       "   (0018, 9603) Diffusion b-value XY                FD: 7.23e+75\n",
       "   (0018, 9604) Diffusion b-value XZ                FD: 7.23e+75\n",
       "   (0018, 9605) Diffusion b-value YY                FD: 7.23e+75\n",
       "   (0018, 9606) Diffusion b-value YZ                FD: 7.23e+75\n",
       "   (0018, 9607) Diffusion b-value ZZ                FD: 7.23e+75\n",
       "   (0020, 9072) Frame Laterality                    CS: 'U'\n",
       "   (0020, 9254) Respiratory Interval Time           FD: 0.0\n",
       "   (0020, 9255) Nominal Respiratory Trigger Delay T FD: 0.0\n",
       "   (0020, 9256) Respiratory Trigger Delay Threshold FD: 7.23e+75\n",
       "   (0028, 9001) Data Point Rows                     UL: 1\n",
       "   (0028, 9002) Data Point Columns                  UL: 0\n",
       "   (0028, 9003) Signal Domain Columns               CS: ''\n",
       "   (0028, 9108) Data Representation                 CS: ''\n",
       "   (0040, 9210) LUT Label                           SH: 'Philips'\n",
       "   ---------\n",
       "(2005, 1410) [Unknown]                           IS: '2147483647'\n",
       "(2005, 1412) [Unknown]                           IS: '1'\n",
       "(2005, 1413) [Unknown]                           IS: '1'\n",
       "(2005, 1414) [Unknown]                           SL: 1\n",
       "(2005, 1415) [Unknown]                           SL: 1\n",
       "(2005, 1416) [Unknown]                           CS: 'MAN'\n",
       "(2005, 1418) [Unknown]                           CS: ['STATIC FIELD', 'RF', 'GRADIENT']\n",
       "(2005, 1419) [Unknown]                           CS: ['IEC_FIRST_LEVEL', 'IEC_FIRST_LEVEL', 'IEC_NORMAL']\n",
       "(2005, 141a) [Unknown]                           CS: ''\n",
       "(2005, 141b) [Unknown]                           IS: '0'\n",
       "(2005, 141c) [Unknown]                           IS: '0'\n",
       "(2005, 141d) [Unknown]                           IS: '0'\n",
       "(2005, 1426) [Unknown]                           CS: 'N'\n",
       "(2005, 1428) [Unknown]                           SL: 0\n",
       "(2005, 1429) Private tag data                    CS: ''\n",
       "(2005, 142a) [Unknown]                           CS: 'INITIAL'\n",
       "(2005, 142b) [Unknown]                           CS: 'PARTLY_ACCEPTED'\n",
       "(2005, 142c) [Unknown]                           CS: 'INITIAL'\n",
       "(2005, 142d) [Unknown]                           CS: 'INITIAL'\n",
       "(2005, 142e) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 142f) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 1430) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 1431) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 1432) [Unknown]                           CS: 'N'\n",
       "(2005, 1435) [Unknown]                           CS: 'N'\n",
       "(2005, 1437) [Unknown]                           CS: ''\n",
       "(2005, 143a) [Unknown]                           LT: Array of 26 elements\n",
       "(2005, 143b) [Unknown]                           CS: 'N'\n",
       "(2005, 143f) [Unknown]                           CS: 'N'\n",
       "(2005, 1440) [Unknown]                           FL: 0.0\n",
       "(2005, 1441) [Unknown]                           FL: 0.0\n",
       "(2005, 1442) [Unknown]                           FL: 1.9798812866210938\n",
       "(2005, 1443) [Unknown]                           FL: 0.0\n",
       "(2005, 1444) [Unknown]                           IS: '0'\n",
       "(2005, 1445) [Unknown]                           CS: 'N'\n",
       "(2005, 1446) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 1447) [Unknown]                           FL: 0.0\n",
       "(2005, 1448) [Unknown]                           FL: 1.6999999760721821e+38\n",
       "(2005, 144d) [Unknown]                           CS: 'N'\n",
       "(2005, 144e) [Unknown]                           CS: 'N'\n",
       "(2005, 1492) Private tag data                    FL: 0.48930633068084717\n",
       "(2005, 1553) Private tag data                    FL: 0.0\n",
       "(2005, 1554) Private tag data                    FL: 0.0\n",
       "(2005, 1555) Private tag data                    FL: 0.0\n",
       "(2005, 1556) Private tag data                    FL: 0.0\n",
       "(2005, 1557) Private tag data                    CS: 'NONE'\n",
       "(2005, 1558) Private tag data                    FL: 0.0\n",
       "(2005, 1559) Private tag data                    FL: 0.0\n",
       "(2005, 1560) Private tag data                    IS: '0'\n",
       "(2005, 1561) Private tag data                    FL: 0.0\n",
       "(2005, 1562) Private tag data                    LT: 'N/A'\n",
       "(2005, 1563) Private tag data                    CS: 'LR'\n",
       "(2005, 1564) Private tag data                    CS: 'AP'\n",
       "(2005, 1565) Private tag data                    CS: 'FH'\n",
       "(2005, 1566) Private tag data                    CS: 'FH'\n",
       "(2005, 1568) Private tag data                    IS: '1'\n",
       "(2005, 1571) Private tag data                    IS: '0'\n",
       "(2005, 1572) Private tag data                    FL: 0.0\n",
       "(2005, 1573) Private tag data                    IS: '0'\n",
       "(2005, 1574) Private tag data                    DS: '0.0'\n",
       "(2005, 1575) Private tag data                    DS: '0.0'\n",
       "(2005, 1576) Private tag data                    LT: ''\n",
       "(2005, 1578) Private tag data                    CS: 'NONE'\n",
       "(2005, 1579) Private tag data                    CS: ['NOMIRRORNOFLIP', 'NOMIRRORNOFLIP', 'NOMIRRORNOFLIP']\n",
       "(2005, 1581) Private tag data                    CS: 'FIRSTLEVEL'\n",
       "(2005, 1582) Private tag data                    IS: '0'\n",
       "(2005, 1583) Private tag data                    LT: ''\n",
       "(2005, 1585) Private tag data                    DS: '0.0'\n",
       "(2005, 1586) Private tag data                    LT: ''\n",
       "(2005, 1587) Private tag data                    DS: '0.0'\n",
       "(2050, 0020) Presentation LUT Shape              CS: 'IDENTITY'\n",
       "(7fe0, 0010) Pixel Data                          OW: Array of 1036800 elements"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_data['subj_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Nov 07 12:12:35 2018',\n",
       " '__version__': '1.0',\n",
       " '__globals__': ['cnt3dYXZ', 'lineTRad', 'lineXYZT'],\n",
       " 'cnt3dYXZ': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint16),\n",
       " 'lineTRad': array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=uint8),\n",
       " 'lineXYZT': array([], shape=(0, 4), dtype=uint8),\n",
       " 'Labels': array([[array(['PectMuscle'], dtype='<U10')],\n",
       "        [array(['Mamary Cntr'], dtype='<U11')],\n",
       "        [array(['Nipple'], dtype='<U6')],\n",
       "        [array(['Sternum'], dtype='<U7')],\n",
       "        [array(['Clavicule'], dtype='<U9')],\n",
       "        [array(['LDorsi'], dtype='<U6')],\n",
       "        [array(['Skin'], dtype='<U4')],\n",
       "        [array(['SerratusA'], dtype='<U9')],\n",
       "        [array(['Lesion'], dtype='<U6')],\n",
       "        [array(['New Labl on Prefs'], dtype='<U17')]], dtype=object),\n",
       " 'cmap': array([[0.99990001, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.99990001],\n",
       "        [0.        , 0.99990001, 0.        ],\n",
       "        [0.        , 0.59994001, 0.99990001],\n",
       "        [0.99990001, 0.99990001, 0.        ],\n",
       "        [0.        , 0.99990001, 0.99990001],\n",
       "        [0.99990001, 0.        , 0.99990001],\n",
       "        [0.249975  , 0.49995   , 0.        ],\n",
       "        [0.29997   , 0.29997   , 0.99990001],\n",
       "        [0.59994001, 0.59994001, 0.99990001],\n",
       "        [0.99990001, 0.51994801, 0.19998   ],\n",
       "        [0.99990001, 0.29997   , 0.99990001]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_filepath = f\"{settings.private_data_folderpath}/ID2/annotFile_bkp.mat\"\n",
    "meta_data = scipy.io.loadmat(meta_filepath)\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Dataset* to **MP4 Saver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Conditional MetaBrest Dataset Reader Class (V2)\n",
    "class NCDataset(Dataset):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings: argparse.ArgumentParser,\n",
    "        dataset: str = 'private',\n",
    "        mode: str = 'train',\n",
    "    ):  \n",
    "        \n",
    "        # Dataset Choice\n",
    "        super(NCDataset).__init__(); self.settings = settings\n",
    "        self.mode = mode; self.dataset = dataset\n",
    "        if self.dataset == 'public': self.data_folderpath = self.settings.public_data_folderpath\n",
    "        elif self.dataset == 'private': self.data_folderpath = self.settings.private_data_folderpath\n",
    "        else: print(\"ERROR: Chosen Dataset / Directory does not exist!\")\n",
    "        \n",
    "        # Subject Indexing (Existing or New Version)\n",
    "        subj_listpath = Path(f\"{self.settings.reader_folderpath}/V{self.settings.data_version}\" +\\\n",
    "                             f\"/{self.dataset}_{self.mode}_setV{self.settings.data_version}.txt\")\n",
    "        if subj_listpath.exists():\n",
    "            print(f\"Reading {self.dataset} Dataset Save Files for {self.mode} Set | Version {settings.data_version}\")\n",
    "            self.subj_list = subj_listpath.read_text().splitlines()\n",
    "        else:\n",
    "            print(f\"Generating New Save Files for {self.dataset} Dataset | Version {settings.data_version}\")\n",
    "            self.subj_list = os.listdir(self.data_folderpath)       # Complete List of Subjects in Dataset\n",
    "            self.subj_list = self.subj_split(self.subj_list)        # Selected List of Subjects in Dataset\n",
    "        #assert len(self.subj_list) == self.num_subj, f\"WARNING: Number of subjs does not match Dataset Version!\"\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Dataset Transformations Initialization\n",
    "        self.transform = transforms.Compose([\n",
    "                                        transforms.Resize(( self.settings.img_size,\n",
    "                                                            self.settings.img_size)),\n",
    "                                        transforms.ToTensor()])\n",
    "        self.h_flip = transforms.Compose([transforms.RandomHorizontalFlip(p = 1)])\n",
    "        self.v_flip = transforms.Compose([transforms.RandomVerticalFlip(p = 1)])\n",
    "\n",
    "    # ============================================================================================\n",
    "\n",
    "    # DataLoader Length / No. Subjects Computation Functionality\n",
    "    def __len__(self): return len(self.subj_list)\n",
    "    \n",
    "    # Subject Splitting Functionality\n",
    "    def subj_split(self, subj_list: list):\n",
    "\n",
    "        # Dataset Splitting\n",
    "        train_subj = len(subj_list) if self.settings.train_subj == 0 else self.settings.train_subj\n",
    "        assert 0 < (train_subj + self.settings.val_subj + self.settings.test_subj) <= len(subj_list),\\\n",
    "               f\"ERROR: Dataset does not contain {train_subj + self.settings.val_subj + self.settings.test_subj} Subjects!\"\n",
    "        train_subj = np.sort(np.array(random.sample(subj_list, train_subj), dtype = 'str'))\n",
    "        subj_list = [subj for subj in subj_list if subj not in train_subj]                                      # Training Set Splitting\n",
    "        if self.settings.train_subj != 0:\n",
    "            val_subj = np.sort(np.array(random.sample(subj_list, self.settings.val_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in val_subj]                                    # Validation Set Splitting\n",
    "            test_subj = np.sort(np.array(random.sample(subj_list, self.settings.test_subj), dtype = 'str'))\n",
    "            subj_list = [subj for subj in subj_list if subj not in test_subj]                                   # Test Set Splitting\n",
    "            subj_list = np.sort(np.array(subj_list, dtype = 'str'))\n",
    "        assert len(subj_list) + len(train_subj) + self.settings.val_subj + self.settings.test_subj == len(self.subj_list),\\\n",
    "               f\"ERROR: Dataset Splitting went Wrong!\"\n",
    "\n",
    "        # Dataset Split Saving\n",
    "        if not os.path.isdir(f\"V{self.settings.data_version}\"): os.mkdir(f\"V{self.settings.data_version}\")\n",
    "        if len(train_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_train_setV{self.settings.data_version}.txt\", train_subj, fmt='%s')\n",
    "        if len(subj_list) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_rest_set (V{self.settings.data_version}).txt\", subj_list, fmt='%s')\n",
    "        if self.settings.train_subj != 0:\n",
    "            if len(val_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_val_setV{self.settings.data_version}.txt\", val_subj, fmt='%s')\n",
    "            if len(test_subj) != 0: np.savetxt(f\"V{self.settings.data_version}/{self.dataset}_test_setV{self.settings.data_version}.txt\", test_subj, fmt='%s')\n",
    "        \n",
    "    # ============================================================================================\n",
    "        \n",
    "    # Single Batch / Subject Generation Functionality\n",
    "    def __getitem__(self, idx: int = 0 or str):\n",
    "        \n",
    "        # Subject Folder Access\n",
    "        subj_idx = idx if type(idx) == str else self.subj_list[idx]\n",
    "        subj_folderpath = f\"{self.data_folderpath}/{subj_idx}\"\n",
    "        subj_filelist = os.listdir(subj_folderpath); i = 0\n",
    "        while len(subj_filelist) > 0 and len(subj_filelist) <= 3:\n",
    "            subj_folderpath = Path(f\"{subj_folderpath}/{subj_filelist[0]}\")\n",
    "            subj_filelist = os.listdir(subj_folderpath)\n",
    "        while os.path.splitext(f\"{subj_folderpath}/{subj_filelist[i]}\")[1] not in ['', '.dcm']: i += 1\n",
    "\n",
    "        # Subject General Information Access\n",
    "        #print(f\"Accessing Subject {subj_idx}: {len(subj_filelist) - i} Slices\")\n",
    "        subj_filepath = Path((f\"{subj_folderpath}/{subj_filelist[i]}\"))\n",
    "        subj_info = pydicom.dcmread(subj_filepath)\n",
    "        subj_ori = subj_info[0x0020, 0x0037].value\n",
    "        subj_v_flip = (np.all(subj_ori == [-1, 0, 0, 0, -1, 0]))\n",
    "        subj_h_flip = (torch.rand(1) < (self.settings.h_flip / 100))\n",
    "        #num_row = subj_info.Rows; num_col = subj_info.Columns\n",
    "        #if self.dataset == 'private':\n",
    "            #num_slice = int(subj_info[0x2001, 0x1018].value)\n",
    "            #preg_status = int(subj_info[0x0010, 0x21c0].value)\n",
    "        #else:\n",
    "            #num_slice = int(subj_info[0x0020, 0x1002].value)\n",
    "            #preg_status = None\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "            \n",
    "        # Subject Slice Data Access\n",
    "        img_data = torch.empty((70, self.settings.img_size, self.settings.img_size)); slice_list = []\n",
    "        for slice_filepath in subj_filelist:\n",
    "            if os.path.splitext(slice_filepath)[1] in ['', '.dcm']:\n",
    "                \n",
    "                # Slice Data Access\n",
    "                slice_filepath = Path(f\"{subj_folderpath}/{slice_filepath}\")\n",
    "                slice_data = pydicom.dcmread(slice_filepath, force=True)\n",
    "                slice_idx = int(slice_data[0x0020, 0x0013].value) - 1\n",
    "                slice_list.append(slice_idx)\n",
    "                img_slice = slice_data.pixel_array.astype(float)\n",
    "\n",
    "                # Slice Image Pre-Processing | Rescaling, Resizing & Flipping\n",
    "                if self.settings.data_prep:\n",
    "                    img_slice = np.uint8((np.maximum(img_slice, 0) / img_slice.max()) * 255)\n",
    "                    img_slice = Image.fromarray(img_slice).resize(( self.settings.img_size,\n",
    "                                                                    self.settings.img_size)) \n",
    "                    if subj_h_flip: img_slice = self.h_flip(img_slice)\n",
    "                    if subj_v_flip: img_slice = self.v_flip(img_slice)\n",
    "                    img_slice = np.array(self.transform(img_slice))\n",
    "                img_data[slice_idx, :, :] = torch.Tensor(img_slice); del img_slice\n",
    "        img_data = img_data[np.sort(slice_list)]\n",
    "\n",
    "        # --------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Correction for Chosen Number of Slices\n",
    "        extra_slice = self.settings.num_slice - img_data.shape[0]\n",
    "        if img_data.shape[0] < self.settings.num_slice:             # Addition of Repeated Peripheral Slices\n",
    "            for extra in range(extra_slice):\n",
    "                if extra % 2 == 0: img_data = torch.cat((img_data, img_data[-1].unsqueeze(0)), dim = 0)\n",
    "                else: img_data = torch.cat((img_data[0].unsqueeze(0), img_data), dim = 0)\n",
    "        elif img_data.shape[0] > self.settings.num_slice:           # Removal of Emptier Peripheral Slices\n",
    "            img_data = img_data[int(np.ceil(-extra_slice / 2)) :\\\n",
    "                int(len(img_data) - np.floor(-extra_slice / 2))]\n",
    "        #else: assert(num_slice == self.settings.num_slice)\n",
    "          \n",
    "        # Item Dictionary Returning\n",
    "        torchvision.io.write_video(f\"{self.data_folderpath}/video_data/V{self.settings.data_version}/{self.mode}/{subj_idx}.mp4\",\n",
    "                                    img_data.unsqueeze(0).swapaxes(0, 3).swapaxes(0, 1).swapaxes(1, 2), fps = self.settings.num_fps)\n",
    "        #return img_data.unsqueeze(0).swapaxes(0, 3)\n",
    "        \"\"\"return {'img_data': img_data,#.unsqueeze(0),\n",
    "                'resolution': f'[{num_row}, {num_col}]',\n",
    "                'subj_id': subj_idx, 'num_slice': num_slice,\n",
    "                'preg_status': preg_status, 'orientation': subj_ori,\n",
    "                'h_flip': subj_h_flip, 'v_flip': subj_v_flip,\n",
    "                'position': str(subj_info[0x0018, 0x5100].value),\n",
    "                'num_series': int(subj_info.SeriesNumber)}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 64, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.swapaxes(1, 3).swapaxes(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading public Dataset Save Files for train Set | Version 0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset Saving Example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m NCDataset(settings,\n\u001b[0;32m      3\u001b[0m                     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#for i in range(len(dataset)): dataset.__getitem__(i)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 140\u001b[0m, in \u001b[0;36mNCDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    135\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m img_data[\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)) :\\\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img_data) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))]\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#else: assert(num_slice == self.settings.num_slice)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m   \n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Item Dictionary Returning\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folderpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/video_data/V\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubj_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_fps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#return img_data.unsqueeze(0).swapaxes(0, 3)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"return {'img_data': img_data,#.unsqueeze(0),\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m        'resolution': f'[{num_row}, {num_col}]',\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        'subj_id': subj_idx, 'num_slice': num_slice,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m        'position': str(subj_info[0x0018, 0x5100].value),\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m        'num_series': int(subj_info.SeriesNumber)}\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:82\u001b[0m, in \u001b[0;36mwrite_video\u001b[1;34m(filename, video_array, fps, video_codec, options, audio_array, audio_fps, audio_codec, audio_options)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m     81\u001b[0m     _log_api_usage_once(write_video)\n\u001b[1;32m---> 82\u001b[0m \u001b[43m_check_av_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m video_array \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(video_array, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# PyAV does not support floating point numbers with decimal point\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# and will throw OverflowException in case this is not the case\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset Saving Example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m NCDataset(settings,\n\u001b[0;32m      3\u001b[0m                     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#for i in range(len(dataset)): dataset.__getitem__(i)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 140\u001b[0m, in \u001b[0;36mNCDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    135\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m img_data[\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)) :\\\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img_data) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))]\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#else: assert(num_slice == self.settings.num_slice)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m   \n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Item Dictionary Returning\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folderpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/video_data/V\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubj_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_fps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#return img_data.unsqueeze(0).swapaxes(0, 3)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"return {'img_data': img_data,#.unsqueeze(0),\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m        'resolution': f'[{num_row}, {num_col}]',\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        'subj_id': subj_idx, 'num_slice': num_slice,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m        'position': str(subj_info[0x0018, 0x5100].value),\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m        'num_series': int(subj_info.SeriesNumber)}\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:82\u001b[0m, in \u001b[0;36mwrite_video\u001b[1;34m(filename, video_array, fps, video_codec, options, audio_array, audio_fps, audio_codec, audio_options)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m     81\u001b[0m     _log_api_usage_once(write_video)\n\u001b[1;32m---> 82\u001b[0m \u001b[43m_check_av_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m video_array \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(video_array, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# PyAV does not support floating point numbers with decimal point\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# and will throw OverflowException in case this is not the case\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset Saving Example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m NCDataset(settings,\n\u001b[0;32m      3\u001b[0m                     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#for i in range(len(dataset)): dataset.__getitem__(i)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 140\u001b[0m, in \u001b[0;36mNCDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    135\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m img_data[\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)) :\\\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(img_data) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;241m-\u001b[39mextra_slice \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))]\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#else: assert(num_slice == self.settings.num_slice)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m   \n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Item Dictionary Returning\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folderpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/video_data/V\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubj_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_fps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m#return img_data.unsqueeze(0).swapaxes(0, 3)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"return {'img_data': img_data,#.unsqueeze(0),\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m        'resolution': f'[{num_row}, {num_col}]',\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        'subj_id': subj_idx, 'num_slice': num_slice,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m        'position': str(subj_info[0x0018, 0x5100].value),\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m        'num_series': int(subj_info.SeriesNumber)}\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:82\u001b[0m, in \u001b[0;36mwrite_video\u001b[1;34m(filename, video_array, fps, video_codec, options, audio_array, audio_fps, audio_codec, audio_options)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m     81\u001b[0m     _log_api_usage_once(write_video)\n\u001b[1;32m---> 82\u001b[0m \u001b[43m_check_av_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m video_array \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(video_array, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# PyAV does not support floating point numbers with decimal point\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# and will throw OverflowException in case this is not the case\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\io\\video.py:41\u001b[0m, in \u001b[0;36m_check_av_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_av_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(av, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m av\n",
      "\u001b[1;31mImportError\u001b[0m: PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Saving Example\n",
    "dataset = NCDataset(settings,\n",
    "                    mode = 'train',\n",
    "                    dataset = 'public')\n",
    "dataset.__getitem__(0)\n",
    "#for i in range(len(dataset)): dataset.__getitem__(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Video** *Diffusion*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation** *Metrics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fréchet Inception Distance Score** (*FID Score*)\n",
    "\n",
    "- https://lightning.ai/docs/torchmetrics/stable/image/frechet_inception_distance.html\n",
    "- https://pytorch.org/torcheval/main/generated/torcheval.metrics.FrechetInceptionDistance.html\n",
    "- https://github.com/mseitzer/pytorch-fid/tree/master\n",
    "\n",
    "**3D Structural Similarity Index** (*3D SSIM Index*)\n",
    "\n",
    "- https://github.com/jinh0park/pytorch-ssim-3D/tree/master\n",
    "\n",
    "**Sorensen-Dice Coefficient** (*Dice Score*)\n",
    "\n",
    "- https://medium.com/@saba99/dice-or-dice-score-fa9f70422db4\n",
    "- https://copyprogramming.com/howto/dice-coefficient-image-segmentation-python\n",
    "\n",
    "**Inception Score** (*IS Loss*)\n",
    "\n",
    "- https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/\n",
    "- https://kailashahirwar.medium.com/a-very-short-introduction-to-inception-score-is-c9b03a7dd788\n",
    "\n",
    "**Normalized Mutual Information** (*NMI Loss*)\n",
    "\n",
    "**Peak Signal-to-Noise Ratio** (*PSNR Loss*)\n",
    "\n",
    "- https://scikit-image.org/docs/stable/api/skimage.metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics) (2.1.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\sousa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-fidelity in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (1.25.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (10.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (1.11.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (0.16.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity) (4.66.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->torch-fidelity) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision->torch-fidelity) (2.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch-fidelity) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch->torch-fidelity) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision->torch-fidelity) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision->torch-fidelity) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision->torch-fidelity) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision->torch-fidelity) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch->torch-fidelity) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\sousa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics[image] in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (2.1.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (0.10.1)\n",
      "Requirement already satisfied: torchvision>=0.8 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (0.16.2)\n",
      "Requirement already satisfied: scipy>1.0.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (1.11.2)\n",
      "Requirement already satisfied: torch-fidelity<=0.4.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchmetrics[image]) (0.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics[image]) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics[image]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics[image]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics[image]) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.10.0->torchmetrics[image]) (2023.10.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (10.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (4.66.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision>=0.8->torchmetrics[image]) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.10.0->torchmetrics[image]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision>=0.8->torchmetrics[image]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision>=0.8->torchmetrics[image]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision>=0.8->torchmetrics[image]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision>=0.8->torchmetrics[image]) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.10.0->torchmetrics[image]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sousa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch-fidelity<=0.4.0->torchmetrics[image]) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\sousa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ssim3d_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 3D SSIM Index Requisites (Pip Package)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#%pip install pytorch_ssim\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#import pytorch_ssim\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#from pytorch_ssim import ssim3D\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 3D SSIM Index Requisites (Local Package)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28meval\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mssim3d_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ssim3D\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Inception Score Requisites\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ssim3d_metric'"
     ]
    }
   ],
   "source": [
    "# FID Score Requisites\n",
    "%pip install torchmetrics\n",
    "%pip install torch-fidelity\n",
    "%pip install torchmetrics[image]\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance as FID\n",
    "\n",
    "# 3D SSIM Index Requisites (Pip Package)\n",
    "#%pip install pytorch_ssim\n",
    "#import pytorch_ssim\n",
    "#from pytorch_ssim import ssim3D\n",
    "\n",
    "# 3D SSIM Index Requisites (Local Package)\n",
    "sys.path.append('eval')\n",
    "from ssim3d_metric import ssim3D\n",
    "\n",
    "\"\"\"\n",
    "# Inception Score Requisites\n",
    "import keras\n",
    "from keras.applications.inception_v3 import preprocess_input, InceptionV3\n",
    "%pip install opencv-python\n",
    "import cv2\n",
    "\"\"\"\n",
    "\n",
    "# Dice Score, PSNR  Requisites\n",
    "\n",
    "%pip install scikit-image\n",
    "import skimage\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import normalized_mutual_information as NMI\n",
    "from skimage.filters import threshold_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Dice Score Functionality\n",
    "def dice_score(input_img, gen_img):\n",
    "\n",
    "    # Image Binarization (Li's Method)\n",
    "    #x_thresh, x = cv2.threshold(x, 128, 192, cv2.THRESH_OTSU)\n",
    "    #y_thresh, y = cv2.threshold(y, 128, 192, cv2.THRESH_OTSU)\n",
    "    input_img = input_img > threshold_li(input_img)\n",
    "    gen_img = gen_img > threshold_li(gen_img)\n",
    "    #print(x_thresh, y_thresh)\n",
    "\n",
    "    # Dice Score Computation\n",
    "    intersect = np.sum(input_img * gen_img)\n",
    "    if (np.sum(input_img) == 0) and (np.sum(gen_img) == 0): return 1\n",
    "    return (2 * intersect) / (np.sum(input_img) + np.sum(gen_img))\n",
    "\n",
    "# Mean Dice Score Functionality\n",
    "def mean_dice_score(input_img, gen_img):\n",
    "    assert(np.all(input_img.shape == gen_img.shape)); mean_score = 0.\n",
    "    if type(input_img) == torch.Tensor:\n",
    "        input_img = input_img.numpy(); gen_img = gen_img.numpy()\n",
    "    for i in range(input_img.shape[0]):\n",
    "        for j in range(input_img.shape[1]):\n",
    "            score = dice_score(input_img[i, j, :, :], gen_img[i, j, :, :])\n",
    "            mean_score += score / (input_img.shape[1] * input_img.shape[0])\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Score Functionality (WIP)\n",
    "def inception_score(\n",
    "    inception_model,\n",
    "    gen_img,\n",
    "    num_split: int = 10,\n",
    "    eps: float = 1e-16\n",
    "):\n",
    "\n",
    "    # Inception Score Computation\n",
    "    y_hat = inception_model.predict(gen_img); is_score = list()\n",
    "    num_part = np.floor(gen_img.shape[0] / num_split)\n",
    "    for i in range(num_split):\n",
    "        idx_start, idx_end = i * num_part, (i * num_part) + num_part\n",
    "        prob_yx = y_hat[idx_start : idx_end]\n",
    "        prob_y = np.expand_dims(prob_yx.mean(axis = 0), 0)\n",
    "        kld_div = prob_yx * (np.log(prob_yx + eps) - np.log(prob_y + eps))\n",
    "        is_score.append(np.exp(np.mean(kld_div.sum(axis = 1))))\n",
    "    return np.mean(is_score), np.std(is_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 12.622090339660645\n",
      "3D SSIM Index: 0.002742826472967863\n",
      "Dice Score: 0.567898018767666\n",
      "PSNR Loss: 7.771684037037087\n",
      "NMI Loss: 1.0044343481596893\n"
     ]
    }
   ],
   "source": [
    "# FID Score Computation Example\n",
    "img1 = torch.randint(0, 200, (100, 3, 299, 299), dtype = torch.uint8)\n",
    "img2 = torch.randint(100, 255, (100, 3, 299, 299), dtype = torch.uint8)\n",
    "fid_metric = FID(feature = 64)\n",
    "fid_metric.update(img1, real = True)\n",
    "fid_metric.update(img2, real = False)\n",
    "print(f\"FID Score: {fid_metric.compute()}\")\n",
    "\n",
    "# 3D SSIM Index Computation Example\n",
    "img1 = torch.randn(1, 1, 30, 64, 64)\n",
    "img2 = torch.randn(1, 1, 30, 64, 64)\n",
    "print(f\"3D SSIM Index: {ssim3D(img1, img2)}\")\n",
    "\n",
    "# Binarization and Dice Score Computation Example\n",
    "img1 = torch.randn(1, 30, 64, 64)\n",
    "img2 = torch.randn(1, 30, 64, 64)\n",
    "print(f\"Dice Score: {mean_dice_score(img1, img2)}\")\n",
    "\n",
    "\"\"\"\n",
    "# Inception Score Computation Example (WIP)\n",
    "img2 = torch.randn(1, 64, 64, 3)\n",
    "inception_model = InceptionV3()\n",
    "is_mean, is_std = inception_score(inception_model, img2)\n",
    "print(f\"Inception Score: {is_mean} +- {is_std}\")\n",
    "\"\"\"\n",
    "\n",
    "#NMI & PSNR Loss Computation Examples\n",
    "img1 = torch.randn(1, 30, 64, 64).numpy()\n",
    "img2 = torch.randn(1, 30, 64, 64).numpy()\n",
    "img1 -= img1.min(1, keepdim=True)[0]\n",
    "img1 /= img1.max(1, keepdim=True)[0]\n",
    "img2 -= img2.min(1, keepdim=True)[0]\n",
    "img2 /= img2.max(1, keepdim=True)[0]\n",
    "print(f\"PSNR Loss: {PSNR(img1, img2)}\")\n",
    "print(f\"NMI Loss: {NMI(img1, img2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Blackout** *Diffusion*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Architectural** *Layers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Position Bias Layer Class\n",
    "class RelativePosBias(nn.Module):\n",
    "\n",
    "  # Description:  It is more effective than Positional Embeddings because it uses\n",
    "  #               Self-Attention to also encode the distance between any 2 tokens,\n",
    "  #               thus providing more flexibility and eliminating the need to input\n",
    "  #               this distance manually.\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "      self,\n",
    "      settings\n",
    "      #num_head: int = 8,\n",
    "      #num_bucket: int = 32,\n",
    "      #max_dist: int = 128\n",
    "  ):\n",
    "    super().__init__(); self.settings = settings\n",
    "    self.rel_attn_bias = nn.Embedding(self.settings.num_bucket, self.settings.num_head)\n",
    "\n",
    "  # --------------------------------------------------------------------------------------------\n",
    "\n",
    "  @static_method\n",
    "  def rel_pos_bucket(\n",
    "    rel_pos,\n",
    "    num_bucket: int = 32,\n",
    "    max_dist = 128\n",
    "  ):\n",
    "    ret = 0; num_bucket //= 2; n = -rel_pos; max_exact = num_bucket // 2\n",
    "    ret += (n < 0).long() * num_bucket; n = torch.abs(n)\n",
    "    value = max + torch.log(n.float() / max_exact) / math.log(max_dist\\\n",
    "                          / max_exact) * (num_bucket - max_exact)).long()\n",
    "    value = torch.min(value, torch.full_like(value, num_bucket - 1))\n",
    "    return ret + torch.where(n < max_exact, n, value)\n",
    "\n",
    "  # --------------------------------------------------------------------------------------------\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      n: int = 0\n",
    "  ):\n",
    "\n",
    "    # Relative Position Embeddings Computation\n",
    "    q = torch.arange(n, dtype = torch.long, device = self.settings.device)\n",
    "    k = torch.arange(n, dtype = torch.long, device = self.settings.device)\n",
    "    rp = rearrange(k, 'j -> 1 j') - rearrange(q, 'i -> i 1')\n",
    "    rp_bucket = self.rel_pos_bucket(rp, num_bucket = self.settings.num_bucket,\n",
    "                                        max_dist = self.settings.max_dist)\n",
    "    return rearrange(self.rel_attn_bias(rp_bucket), 'i j h -> h i j')\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Sinusoidal Position Embedding Layer Class\n",
    "class SinusoidalPosEmbedding(nn.Module):\n",
    "\n",
    "  # Description:  This Module will take as Input the Noise Levels of all the\n",
    "  #               Images in the Batch [batch_size, 1] and return a tensor\n",
    "  #               containing the Position Embeddings' Dimensionality\n",
    "  #               [batch_size, dim] so it can be added to the Residual Blocks.\n",
    "  # Source:       https://arxiv.org/abs/1706.03762\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "      self,\n",
    "      dim: int\n",
    "  ):  super().__init__(); self.dim = dim\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      ts: int = 0\n",
    "  ):\n",
    "\n",
    "    # Position Embeddings Computation\n",
    "    embed = math.log(10000) / ((self.dim // 2) - 1)\n",
    "    embed = torch.exp(torch.arange(self.dim // 2, device = ts.device) * (-embed))\n",
    "    embed = ts[:, None] * embed[None, :]\n",
    "    return torch.cat((embed.sin(), embed.cos()), dim = -1)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Residual Connection Layer Class\n",
    "class Residual(nn.Module):\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "      self,\n",
    "      fn\n",
    "  ):  super().__init__(); self.fn = fn\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      x: torch.Tensor,\n",
    "      *args,\n",
    "      **kwargs\n",
    "  ): return self.fn(x, *args, **kwargs) + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling Layer Functionality\n",
    "def Downsample(dim: int):\n",
    "  return nn.Conv3d( dim, dim, kernel_size = (1, 4, 4),\n",
    "                    stride = (1, 2, 2), padding = (0, 1, 1))\n",
    "\n",
    "# Upsampling Layer Functionality\n",
    "def Upsample(dim: int):\n",
    "  return nn.ConvTranspose3d(dim, dim, kernel_size = (1, 4, 4),\n",
    "                            stride = (1, 2, 2), padding = (0, 1, 1))\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Helper Functionalities\n",
    "def default(val, d):\n",
    "  if exists(val): return val\n",
    "  return d() if isfunction(d) else d\n",
    "\n",
    "def exists(x): return x is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary Group Normalization Layer Class\n",
    "class PreNorm(nn.Module):\n",
    "\n",
    "  # Description:  Group Normalization is applied before Attention\n",
    "  #               although this is contentional in literature\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "    self,\n",
    "    dim: int,\n",
    "    fn\n",
    "  ):\n",
    "\n",
    "    # Layer Architecture Definition\n",
    "    super().__init__(); self.fn = fn\n",
    "    self.norm = LayerNorm(dim)\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      x,\n",
    "      **kwargs\n",
    "  ):  return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "# ============================================================================================\n",
    "\n",
    "# Preliminary Group Normalization Layer Class\n",
    "class PreNorm(nn.Module):\n",
    "\n",
    "  # Description:  Group Normalization is applied before Attention\n",
    "  #               although this is contentional in literature\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "    self,\n",
    "    dim: int,\n",
    "    fn\n",
    "  ):\n",
    "\n",
    "    # Layer Architecture Definition\n",
    "    super().__init__(); self.fn = fn\n",
    "    self.norm = LayerNorm(dim)\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      x,\n",
    "      **kwargs\n",
    "  ):  return self.fn(self.norm(x), **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer Class\n",
    "class Attention(nn.Module):\n",
    "\n",
    "  # Constructor / Initialization Function\n",
    "  def __init__(\n",
    "      self,\n",
    "      dim: int,\n",
    "      layer: str = 'quadratic',\n",
    "      num_head: int = 4,\n",
    "      head_dim: int = 32\n",
    "  ):\n",
    "\n",
    "    # Layer Architecture Definition\n",
    "    super().__init__(); self.layer = layer; self.num_head = num_head\n",
    "    self.scale = head_dim ** (-0.5); hidden_dim = head_dim * num_head\n",
    "    self.conv1 = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
    "    if self.layer == 'quadratic': self.conv2 = nn.Conv2d(hidden_dim, dim, 1)\n",
    "    else: self.conv2 = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1), nn.GroupNorm(1, dim))\n",
    "\n",
    "  # --------------------------------------------------------------------------------------------\n",
    "\n",
    "  # Layer Application Function\n",
    "  def forward(\n",
    "      self,\n",
    "      x\n",
    "  ):\n",
    "\n",
    "    # Layer Application\n",
    "    b, c, h, w = x.shape; qkv = self.conv1(x).chunk(3, dim = 1)\n",
    "    q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)',\n",
    "                                      h = self.num_head), qkv)\n",
    "\n",
    "    # Quadratic Attention Layer Application\n",
    "    if self.layer == 'quadratic':\n",
    "      q = q * self.scale\n",
    "      sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "      sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
    "      attn = sim.softmax(dim = -1)\n",
    "      out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "      out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n",
    "\n",
    "    # Linear Attention Layer Application\n",
    "    elif self.layer == 'linear':\n",
    "      q = q.softmax(dim = -2) * self.scale; k = k.softmax(dim = -1)\n",
    "      context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "      out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "      out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.num_head, x = h, y = w)\n",
    "\n",
    "    else: print(f\"ERROR: '{self.layer}' is not a valid Attention Layer type!\"); return 0\n",
    "    return self.conv2(out)\n",
    "\n",
    "# ============================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Diffusion** *Process*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting intel-openmpNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading intel_openmp-2024.0.2-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Downloading intel_openmp-2024.0.2-py2.py3-none-win_amd64.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.9 MB 325.1 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.1/3.9 MB 544.7 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.3/3.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/3.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.0/3.9 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.5/3.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.9/3.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.2/3.9 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.7/3.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.0/3.9 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.3/3.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.6/3.9 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.8/3.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: intel-openmp\n",
      "Successfully installed intel-openmp-2024.0.2\n"
     ]
    }
   ],
   "source": [
    "#%pip install ninja\n",
    "%pip install intel-openmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing upfirdn2d: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[405], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(settings\u001b[38;5;241m.\u001b[39mmodel_folderpath)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mncsnpp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n",
      "File \u001b[1;32mc:\\Users\\sousa\\Desktop\\MetaBreast Project\\Home Directory\\models/blackout_diffusion\\ncsnpp.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlayerspp\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnormalization\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sousa\\Desktop\\MetaBreast Project\\Home Directory\\models/blackout_diffusion\\layerspp.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Layers for defining NCSN++.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mup_or_down_sampling\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sousa\\Desktop\\MetaBreast Project\\Home Directory\\models/blackout_diffusion\\up_or_down_sampling.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mupfirdn2d\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Function ported from StyleGAN2\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weight\u001b[39m(module,\n\u001b[0;32m     15\u001b[0m                shape,\n\u001b[0;32m     16\u001b[0m                weight_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m                kernel_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\sousa\\Desktop\\MetaBreast Project\\Home Directory\\models/blackout_diffusion\\upfirdn2d.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[0;32m      9\u001b[0m module_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m upfirdn2d_op \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupfirdn2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupfirdn2d.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupfirdn2d_kernel.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUpFirDn2dBackward\u001b[39;00m(Function):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     22\u001b[0m         ctx, grad_output, kernel, grad_kernel, up, down, pad, g_pad, in_size, out_size\n\u001b[0;32m     23\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\cpp_extension.py:1308\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[0;32m   1217\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   1218\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1227\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;124;03m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m-> 1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\cpp_extension.py:1736\u001b[0m, in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[1;32m-> 1736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\cpp_extension.py:2136\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[1;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[0;32m   2134\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2136\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[0;32m   2138\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing upfirdn2d: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "ts_end = 10.\n",
    "offset = 0.01\n",
    "from scipy.optimize import bisect\n",
    "from scipy.stats import binom\n",
    "\n",
    "sys.path.append(settings.model_folderpath)\n",
    "import utils\n",
    "import ncsnpp\n",
    "from config_loader import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blackout Diffusion Process Class\n",
    "#def f(x): np.log(x / (1 - x))\n",
    "class BlackoutDiffusion(nn.Module):\n",
    "\n",
    "    # Constructor / Initialization Function\n",
    "    def __init__(\n",
    "        self,\n",
    "        settings\n",
    "    ):\n",
    "        \n",
    "        # Weight Initialization\n",
    "        super().__init__(); self.settings = settings; self.solution_init()\n",
    "        self.cdf = torch.from_numpy(self.cdf).to(self.settings.device)\n",
    "        self.br_table = torch.from_numpy(np.ravel(self.br_table)).to(self.settings.device)\n",
    "        observ_time = np.hstack([0, self.observ]); pt = np.exp(-observ_time[1:])\n",
    "        self.observ = torch.from_numpy(self.observ).to(self.settings.device)\n",
    "        #ps, pt = np.exp(-observ_time[:-1]), np.exp(-observ_time[1:])\n",
    "        #self.prob_sample = np.ones_like(pt) / np.sum(np.ones_like(pt))\n",
    "        self.prob_sample = np.ones_like(pt); self.prob_sample /= np.sum(self.prob_sample)\n",
    "        self.weight = pt / self.prob_sample * (observ_time[1:] - observ_time[:-1])\n",
    "        self.weight = torch.from_numpy(self.weight).to(self.settings.device)\n",
    "\n",
    "        # Transition Rate Scoring Model Initialization\n",
    "        #model = mutils\n",
    "    \n",
    "    # ============================================================================================\n",
    "\n",
    "    \"\"\"\n",
    "    # Analytical Derivation of Forward Diffusion Process Functionality\n",
    "    def solution_init(self):\n",
    "        \n",
    "        # Previous Solution Reading Attempt\n",
    "        self.solution_filepath = Path(f\"{settings.logs_folderpath}/V{settings.model_version}/solution.npz\")\n",
    "        if self.solution_filepath.exists():\n",
    "            solution = np.load(self.solution_filepath)\n",
    "            self.cdf = solution['cdf']\n",
    "            self.br_table = solution['br_table']\n",
    "            self.observ = solution['observ']\n",
    "        else:\n",
    "\n",
    "            # Function Variable initialization\n",
    "            x_end = np.exp(-settings.ts_end)\n",
    "            f_grid = np.linspace(   -np.log(x_end / (1 - x_end)),\n",
    "                                    np.log(x_end / (1 - x_end)), settings.num_ts)\n",
    "            x_grid = np.array([bisect(  lambda x: np.log(x / (1 - x)) - f_grid[i], \n",
    "                x_end / 2, 1 - x_end / 2) for i in range(settings.num_ts)])\n",
    "            self.observ = -np.log(x_grid)\n",
    "\n",
    "            # Reverse-Time Transition Rate Analytical Derivation\n",
    "            self.br_table = np.zeros((  settings.dim,\n",
    "                        settings.dim, settings.num_ts))\n",
    "            for ts_idx in range(settings.num_ts):\n",
    "                prob = np.exp(-self.observ[ts_idx])\n",
    "                for n in range(settings.dim):\n",
    "                    for m in range(n):\n",
    "                        self.br_table[n, m, ts_idx] = n - m\n",
    "                    self.br_table[n, n, ts_idx] = 0\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Forward Process Solution Analytical Derivation | Probability Distribution Function\n",
    "            supp = np.arange(0, settings.dim)\n",
    "            pdf = np.zeros((settings.num_ts + 1,\n",
    "                settings.dim, settings.dim))\n",
    "            pdf[0, :, :] = np.eye(settings.dim)\n",
    "            for ts_idx in range(settings.num_ts):\n",
    "                prob = np.exp(-self.observ[ts_idx])\n",
    "                for ic in range(settings.dim):\n",
    "                    pdf[ts_idx + 1, :, ic] = binom(ic, prob).pmf(supp)\n",
    "\n",
    "            # Forward Process Solution Analytical Derivation | Cumulative Distribution Function\n",
    "            self.cdf = np.zeros_like(pdf)\n",
    "            for i in range(pdf.shape[0]):\n",
    "                for j in range(pdf.shape[1]):\n",
    "                    self.cdf[i, : , j] = np.cumsum(pdf[i, :, j])\n",
    "            #np.savez(   self.solution_filepath, cdf = self.cdf,\n",
    "            #            br_table = self.br_table, observ = self.observ)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Analytical Derivation of Forward Diffusion Process Functionality\n",
    "    def solution_init(self):\n",
    "        \n",
    "        # Previous Solution Reading Attempt\n",
    "        self.solution_filepath = Path(f\"{settings.logs_folderpath}/V{settings.model_version}/solution.npz\")\n",
    "        if self.solution_filepath.exists():\n",
    "            solution = np.load(self.solution_filepath)\n",
    "            self.cdf = solution['cdf']\n",
    "            self.br_table = solution['br_table']\n",
    "            self.observ = solution['observ']\n",
    "        else:\n",
    "\n",
    "            # Function Variable initialization\n",
    "            x_end = np.exp(-settings.ts_end)\n",
    "            f_grid = np.linspace(   -np.log(x_end / (1 - x_end)),\n",
    "                                    np.log(x_end / (1 - x_end)), settings.num_ts)\n",
    "            x_grid = np.array([bisect(  lambda x: np.log(x / (1 - x)) - f_grid[i], \n",
    "                x_end / 2, 1 - x_end / 2) for i in range(settings.num_ts)])\n",
    "            self.observ = -np.log(x_grid)\n",
    "\n",
    "            # Reverse-Time Transition Rate Analytical Derivation\n",
    "            self.br_table = np.zeros((  settings.img_size,\n",
    "                        settings.img_size, settings.num_ts))\n",
    "            for ts_idx in range(settings.num_ts):\n",
    "                prob = np.exp(-self.observ[ts_idx])\n",
    "                for n in range(settings.img_size):\n",
    "                    for m in range(n):\n",
    "                        self.br_table[n, m, ts_idx] = n - m\n",
    "                    self.br_table[n, n, ts_idx] = 0\n",
    "\n",
    "            # --------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Forward Process Solution Analytical Derivation | Probability Distribution Function\n",
    "            supp = np.arange(0, settings.img_size)\n",
    "            pdf = np.zeros((settings.num_ts + 1,\n",
    "                settings.img_size, settings.img_size))\n",
    "            pdf[0, :, :] = np.eye(settings.img_size)\n",
    "            for ts_idx in range(settings.num_ts):\n",
    "                prob = np.exp(-self.observ[ts_idx])\n",
    "                for ic in range(settings.img_size):\n",
    "                    pdf[ts_idx + 1, :, ic] = binom(ic, prob).pmf(supp)\n",
    "\n",
    "            # Forward Process Solution Analytical Derivation | Cumulative Distribution Function\n",
    "            self.cdf = np.zeros_like(pdf)\n",
    "            for i in range(pdf.shape[0]):\n",
    "                for j in range(pdf.shape[1]):\n",
    "                    self.cdf[i, : , j] = np.cumsum(pdf[i, :, j])\n",
    "            #np.savez(   self.solution_filepath, cdf = self.cdf,\n",
    "            #            br_table = self.br_table, observ = self.observ)\n",
    "                \n",
    "    # ============================================================================================\n",
    "                    \n",
    "    # Image Noisifier Functionality\n",
    "    def add_noise(\n",
    "        self,\n",
    "        img: torch.Tensor,      # [batch_size, num_slice, width, height, num_channel]\n",
    "        ts: int = 0\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            noise_img = (img > self.settings.noise_thresh).to(self.settings.device).long()\n",
    "            ts_idx = torch.from_numpy(np.random.choice(ts,\n",
    "                size = (img.shape[0], 1, 1, 1, 1), p = self.prob_sample)).to(self.settings.device)\n",
    "            cdf = self.cdf[(ts_idx + 1).long(), :, noise_img.long()]\n",
    "            \n",
    "            mu = torch.FloatTensor(img.shape[0], img.shape[1], img.shape[2],\n",
    "                img.shape[3], img.shape[4], 1).uniform_().to(self.settings.device)\n",
    "            nt = torch.argmax((mu < cdf).long(), axis = 5).int()\n",
    "            #idx = noise_img * self.settings.dim * ts + nt * ts + ts_idx.long()\n",
    "            idx = noise_img * 256 * ts + nt * ts + ts_idx.long()\n",
    "            birth_rate = self.br_table[idx.long()]\n",
    "\n",
    "            prob = torch.exp(-self.observ[ts_idx.long()])\n",
    "            width = 1.0 #(255.0 / (2 * prob)).reshape((img.shape[0], 1, 1, 1, 1))\n",
    "            v_mean = (1.0 / 2 * prob).reshape((img.shape[0], 1, 1, 1, 1))\n",
    "            return ((nt - v_mean) / width).permute((0, 4, 3, 1, 2)).to(torch.float32),\\\n",
    "                    birth_rate.permute((0, 4, 3, 1, 2)).to(torch.float32), ts_idx[:, 0, 0, 0, 0]\n",
    "        \n",
    "        # ============================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBatchDataGPU(imgBatch,T):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        n,nx,ny,ns,nc = imgBatch.shape\n",
    "        imgBatchGPU = (imgBatch>settings.noise_thresh).to(settings.device).long()\n",
    "        tIndex = torch.from_numpy(np.random.choice(T, size=(n,1,1,1,1), p=diff.prob_sample)).to(settings.device)\n",
    "        \n",
    "        cp = diff.cdf[(tIndex+1).long(),:,imgBatchGPU.long()]\n",
    "        u = torch.FloatTensor(n,nx,ny,ns,nc,1).uniform_().to(settings.device)\n",
    "        \n",
    "        nt =  torch.argmax((u < cp).long(), axis=5).int()\n",
    "        index = imgBatchGPU*256*T + nt*T + tIndex.long()\n",
    "        birthRateBatch = diff.br_table[index.long()]  \n",
    "    \n",
    "        p = torch.exp(-diff.observ[tIndex.long()])\n",
    "        width = 1.0 #(255.0/2*p).reshape((n, 1, 1, 1))\n",
    "        mean_v = (1.0/2*p).reshape((n, 1, 1, 1, 1))\n",
    "        \n",
    "        return ((nt-mean_v)/width).permute((0,4,3,1,2)).to(torch.float32), birthRateBatch.permute((0,4,3,1,2)).to(torch.float32), tIndex[:,0,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sousa\\AppData\\Local\\Temp\\ipykernel_14992\\1774461802.py:11: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  plt.subplot(3, 2, 1, title = \"Original Image\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13a7cbdb610>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Blackout Diffusion Process Initialization\n",
    "diff = BlackoutDiffusion(settings)\n",
    "real_img = data[0].unsqueeze(0).unsqueeze(4).swapaxes(1,3).swapaxes(1,2)         # [batch_size, width, height, num_slice, num_channel]\n",
    "noise_img, birth_rate, ts_idx = diff.add_noise(real_img, ts = settings.num_ts)\n",
    "#noise_img, birth_rate, ts_idx = generateBatchDataGPU(real_img, T = settings.num_ts)\n",
    "\n",
    "# Image Visualization\n",
    "num_slice = 15; br_rate = birth_rate[0, 0, num_slice, :, :].numpy()\n",
    "out_img = ((noise_img[0, 0, num_slice, :, :] * 255.0 + 1.0) / 2.0).numpy().astype('int32')\n",
    "plt.xticks([]); plt.yticks([]); plt.grid(False); plt.tight_layout()\n",
    "plt.subplot(3, 2, 1, title = \"Original Image\")\n",
    "plt.imshow(data[0, num_slice, :, :], cmap = plt.cm.binary)\n",
    "plt.subplot(3, 2, 3, title = \"Noisified Image\")\n",
    "plt.imshow(out_img)#, cmap = plt.cm.binary)\n",
    "plt.subplot(3, 2, 4, title = \"Noisified Image\")\n",
    "plt.imshow(out_img / np.amax(out_img))#, cmap = plt.cm.binary)\n",
    "plt.subplot(3, 2, 5, title = \"Birth Rate\")\n",
    "plt.imshow(br_rate)#, cmap = plt.cm.binary)\n",
    "plt.subplot(3, 2, 6, title = \"Birth Rate\")\n",
    "plt.imshow((br_rate - np.amin(br_rate)) / (np.amax(br_rate) - np.amin(br_rate)))#, cmap = plt.cm.binary)\n",
    "\n",
    "# 3D Blackout Diffusion Process Initialization (WIP)\n",
    "#img = torch.randn(1, 64, 64, 30, 1)\n",
    "#noise_img, birth_rate, ts_idx = diff.add_noise(img, ts = settings.num_ts)\n",
    "#noise_img, birth_rate, ts_idx = diff.add_noise(data.unsqueeze(4), ts = settings.num_ts)                                # [batch_size, width, height, num_slice, num_channel]\n",
    "#noise_img, birth_rate, ts_idx = generateBatchDataGPU(data[0, 15].unsqueeze(0).unsqueeze(3), T = settings.num_ts)       # [batch_size, width, height, num_channel]\n",
    "#noise_img, birth_rate, ts_idx = generateBatchDataGPU(img, T = settings.num_ts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
